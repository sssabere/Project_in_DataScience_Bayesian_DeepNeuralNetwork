{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f39f86f0",
   "metadata": {},
   "source": [
    "## Combine CNNs and Naive Bayes predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "481dc6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx\n",
    "from sklearn.metrics import log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1af8dc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cnn_class_0</th>\n",
       "      <th>cnn_class_1</th>\n",
       "      <th>cnn_class_2</th>\n",
       "      <th>cnn_class_3</th>\n",
       "      <th>cnn_class_4</th>\n",
       "      <th>cnn_class_5</th>\n",
       "      <th>cnn_class_6</th>\n",
       "      <th>cnn_class_7</th>\n",
       "      <th>cnn_class_8</th>\n",
       "      <th>cnn_class_9</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.646409e-01</td>\n",
       "      <td>2.929921e-08</td>\n",
       "      <td>3.541268e-04</td>\n",
       "      <td>2.757727e-04</td>\n",
       "      <td>4.640916e-04</td>\n",
       "      <td>1.097169e-12</td>\n",
       "      <td>2.340744e-01</td>\n",
       "      <td>4.767119e-12</td>\n",
       "      <td>1.905905e-04</td>\n",
       "      <td>1.464011e-14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.475791e-07</td>\n",
       "      <td>9.999992e-01</td>\n",
       "      <td>1.138260e-10</td>\n",
       "      <td>1.559626e-07</td>\n",
       "      <td>5.492502e-07</td>\n",
       "      <td>7.475159e-13</td>\n",
       "      <td>1.660269e-08</td>\n",
       "      <td>1.402884e-13</td>\n",
       "      <td>3.315164e-10</td>\n",
       "      <td>1.397080e-11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.620998e-02</td>\n",
       "      <td>4.265870e-05</td>\n",
       "      <td>2.199001e-01</td>\n",
       "      <td>2.774664e-03</td>\n",
       "      <td>3.708358e-02</td>\n",
       "      <td>8.344720e-06</td>\n",
       "      <td>7.237250e-01</td>\n",
       "      <td>4.747752e-07</td>\n",
       "      <td>2.462436e-04</td>\n",
       "      <td>8.926933e-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.039407e-03</td>\n",
       "      <td>1.616838e-03</td>\n",
       "      <td>8.089375e-01</td>\n",
       "      <td>8.918043e-03</td>\n",
       "      <td>7.218361e-02</td>\n",
       "      <td>6.735617e-09</td>\n",
       "      <td>1.037089e-01</td>\n",
       "      <td>8.984537e-07</td>\n",
       "      <td>1.594747e-03</td>\n",
       "      <td>3.810794e-08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.765935e-04</td>\n",
       "      <td>3.107002e-05</td>\n",
       "      <td>1.534149e-01</td>\n",
       "      <td>6.109465e-01</td>\n",
       "      <td>2.351162e-01</td>\n",
       "      <td>1.557162e-07</td>\n",
       "      <td>1.786349e-04</td>\n",
       "      <td>8.040750e-08</td>\n",
       "      <td>3.520224e-05</td>\n",
       "      <td>6.593066e-07</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   cnn_class_0   cnn_class_1   cnn_class_2   cnn_class_3   cnn_class_4  \\\n",
       "0   0  7.646409e-01  2.929921e-08  3.541268e-04  2.757727e-04  4.640916e-04   \n",
       "1   1  1.475791e-07  9.999992e-01  1.138260e-10  1.559626e-07  5.492502e-07   \n",
       "2   2  1.620998e-02  4.265870e-05  2.199001e-01  2.774664e-03  3.708358e-02   \n",
       "3   3  3.039407e-03  1.616838e-03  8.089375e-01  8.918043e-03  7.218361e-02   \n",
       "4   4  2.765935e-04  3.107002e-05  1.534149e-01  6.109465e-01  2.351162e-01   \n",
       "\n",
       "    cnn_class_5   cnn_class_6   cnn_class_7   cnn_class_8   cnn_class_9  \\\n",
       "0  1.097169e-12  2.340744e-01  4.767119e-12  1.905905e-04  1.464011e-14   \n",
       "1  7.475159e-13  1.660269e-08  1.402884e-13  3.315164e-10  1.397080e-11   \n",
       "2  8.344720e-06  7.237250e-01  4.747752e-07  2.462436e-04  8.926933e-06   \n",
       "3  6.735617e-09  1.037089e-01  8.984537e-07  1.594747e-03  3.810794e-08   \n",
       "4  1.557162e-07  1.786349e-04  8.040750e-08  3.520224e-05  6.593066e-07   \n",
       "\n",
       "   true_label  \n",
       "0           0  \n",
       "1           1  \n",
       "2           2  \n",
       "3           2  \n",
       "4           3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calibrated preds of cnn \n",
    "cnn_preds_test = pd.read_csv(\"cnn_predictions_test.csv\")\n",
    "cnn_preds_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "555373fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nb_class_0</th>\n",
       "      <th>nb_class_1</th>\n",
       "      <th>nb_class_2</th>\n",
       "      <th>nb_class_3</th>\n",
       "      <th>nb_class_4</th>\n",
       "      <th>nb_class_5</th>\n",
       "      <th>nb_class_6</th>\n",
       "      <th>nb_class_7</th>\n",
       "      <th>nb_class_8</th>\n",
       "      <th>nb_class_9</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.248385e-174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  nb_class_0  nb_class_1     nb_class_2  nb_class_3  nb_class_4  \\\n",
       "0   0         1.0         0.0   0.000000e+00         0.0         0.0   \n",
       "1   1         0.0         1.0   0.000000e+00         0.0         0.0   \n",
       "2   2         0.0         0.0   1.000000e+00         0.0         0.0   \n",
       "3   3         0.0         0.0  7.248385e-174         0.0         0.0   \n",
       "4   4         0.0         0.0   0.000000e+00         1.0         0.0   \n",
       "\n",
       "   nb_class_5  nb_class_6  nb_class_7  nb_class_8  nb_class_9  true_label  \n",
       "0         0.0         0.0         0.0         0.0         0.0           0  \n",
       "1         0.0         0.0         0.0         0.0         0.0           1  \n",
       "2         0.0         0.0         0.0         0.0         0.0           2  \n",
       "3         0.0         1.0         0.0         0.0         0.0           2  \n",
       "4         0.0         0.0         0.0         0.0         0.0           3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The predictions for the Naive Bayes classifier are currently not calibrated - I use it as is just to test my part. \n",
    "# Once we have the calibrated preds we can change them.\n",
    "\n",
    "nb_preds_test = pd.read_csv(\"nb_predictions_test.csv\")\n",
    "nb_preds_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b53034d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two datasets \n",
    "cnn_nb_combined_test = cnn_preds_test.merge(nb_preds_test, on=\"id\")\n",
    "\n",
    "# Get the probs for the CNN and NB\n",
    "cnn_probs_test = cnn_nb_combined_test[[f\"cnn_class_{i}\" for i in range(10)]].values\n",
    "nb_probs_test = cnn_nb_combined_test[[f\"nb_class_{i}\" for i in range(10)]].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96387c9d",
   "metadata": {},
   "source": [
    "1. Accurate Probability Calibration for Multiple Classifiers by Leon Wenliang Zhong and James T. Kwok\n",
    "\n",
    "In their paper they use soft voting (averaging the probabilities) to get an ensemble starting point for each class. Then they fit an isotonic regression to make the combined probability well-calibrated and finally optimise using alternating direction method of multipliers (ADMM). \n",
    "\n",
    "I will try to replicate their method and see if it improves the accuracy. (exact steps on the paper page 1942)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b0a5bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "9995    1.0\n",
      "9996    1.0\n",
      "9997    1.0\n",
      "9998    1.0\n",
      "9999    1.0\n",
      "Length: 10000, dtype: float64\n",
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "9995    1.0\n",
      "9996    1.0\n",
      "9997    1.0\n",
      "9998    1.0\n",
      "9999    1.0\n",
      "Length: 10000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Sanity checks \n",
    "\n",
    "# Check if probs sum to 1 for the CNN and NB\n",
    "cnn_sum = cnn_nb_combined_test[[f\"cnn_class_{i}\" for i in range(10)]].sum(axis=1)\n",
    "print(cnn_sum)\n",
    "\n",
    "nb_sum = cnn_nb_combined_test[[f\"nb_class_{i}\" for i in range(10)]].sum(axis=1)\n",
    "print(nb_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0013900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test (average): 66.8%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average prob between CNN and NB \n",
    "avg_probs_test = 0.5 * cnn_probs_test + 0.5 * nb_probs_test\n",
    "\n",
    "# Get the highest (final prediction)\n",
    "avg_preds_test = np.argmax(avg_probs_test, axis=1)\n",
    "y_true_test = cnn_nb_combined_test[\"true_label_y\"].values\n",
    "\n",
    "# Get the accuracy \n",
    "accuracy = (avg_preds_test == y_true_test).mean() * 100\n",
    "print(f\"Accuracy Test (average): {accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ec90e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nb_class_0</th>\n",
       "      <th>nb_class_1</th>\n",
       "      <th>nb_class_2</th>\n",
       "      <th>nb_class_3</th>\n",
       "      <th>nb_class_4</th>\n",
       "      <th>nb_class_5</th>\n",
       "      <th>nb_class_6</th>\n",
       "      <th>nb_class_7</th>\n",
       "      <th>nb_class_8</th>\n",
       "      <th>nb_class_9</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  nb_class_0  nb_class_1  nb_class_2  nb_class_3  nb_class_4  nb_class_5  \\\n",
       "0   0         0.0         1.0         0.0         0.0         0.0         0.0   \n",
       "1   1         1.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2   2         0.0         0.0         0.0         0.0         1.0         0.0   \n",
       "3   3         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4   4         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   nb_class_6  nb_class_7  nb_class_8  nb_class_9  true_label  \n",
       "0         0.0         0.0         0.0         0.0           1  \n",
       "1         0.0         0.0         0.0         0.0           0  \n",
       "2         0.0         0.0         0.0         0.0           8  \n",
       "3         0.0         1.0         0.0         0.0           5  \n",
       "4         1.0         0.0         0.0         0.0           4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation preds of CNN and NB\n",
    "cnn_preds_val = pd.read_csv(\"cnn_predictions_val.csv\")\n",
    "cnn_preds_val.head()\n",
    "\n",
    "nb_preds_val = pd.read_csv(\"nb_predictions_val.csv\")\n",
    "nb_preds_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "043cbae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two datasets \n",
    "cnn_nb_combined_val = cnn_preds_val.merge(nb_preds_val, on=\"id\")\n",
    "\n",
    "# Get the probs for the CNN and NB\n",
    "cnn_probs_val = cnn_nb_combined_val[[f\"cnn_class_{i}\" for i in range(10)]].values\n",
    "nb_probs_val = cnn_nb_combined_val[[f\"nb_class_{i}\" for i in range(10)]].values\n",
    "\n",
    "y_true_val = cnn_nb_combined_val[\"true_label_y\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ad0013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Val (average): 66.0111111111111%\n"
     ]
    }
   ],
   "source": [
    "# Repeat for validation\n",
    "avg_probs_val = 0.5 * cnn_probs_val + 0.5 * nb_probs_val\n",
    "avg_preds_val = np.argmax(avg_probs_val, axis=1)\n",
    "\n",
    "accuracy_val = (avg_preds_val == y_true_val).mean() * 100\n",
    "print(f\"Accuracy Val (average): {accuracy_val}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01d9182e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL Val (average): 0.47425961043747994\n",
      "NLL Test (average): 0.46148764800955333\n",
      "ECE Val (average): 0.16610358190839664\n",
      "ECE Test (average): 0.16395596667470533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Calculate NLL and ECE for validation and testing set \n",
    "nll_val = log_loss(y_true_val, avg_probs_val, labels=np.arange(10))\n",
    "print(f\"NLL Val (average): {nll_val}\")\n",
    "\n",
    "nll_test = log_loss(y_true_test, avg_probs_test, labels=np.arange(10))\n",
    "print(f\"NLL Test (average): {nll_test}\")\n",
    "\n",
    "def ece_score(probs, labels, n_bins=15):\n",
    "    confidences = probs.max(axis=1)\n",
    "    predictions = probs.argmax(axis=1)\n",
    "    accuracies = (predictions == labels)\n",
    "\n",
    "    bins = np.linspace(0, 1, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        mask = (confidences > bins[i]) & (confidences <= bins[i+1])\n",
    "        if mask.any():\n",
    "            bin_acc = accuracies[mask].mean()\n",
    "            bin_conf = confidences[mask].mean()\n",
    "            ece += np.abs(bin_acc - bin_conf) * mask.mean()\n",
    "    return ece\n",
    "\n",
    "ece_val = ece_score(avg_probs_val, y_true_val)\n",
    "print(f\"ECE Val (average): {ece_val}\")\n",
    "\n",
    "ece_test = ece_score(avg_probs_test, y_true_test)\n",
    "print(f\"ECE Test (average): {ece_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2880bbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test (average): 66.8%\n",
      "Accuracy Val (average): 66.0111111111111%\n",
      "\n",
      "NLL Val (average): 0.47425961043747994\n",
      "NLL Test (average): 0.46148764800955333\n",
      "\n",
      "ECE Val (average): 0.16610358190839664\n",
      "ECE Test (average): 0.16395596667470533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All results for simple average (50/50)\n",
    "\n",
    "print(f\"Accuracy Test (average): {accuracy}%\")\n",
    "print(f\"Accuracy Val (average): {accuracy_val}%\")\n",
    "print()\n",
    "\n",
    "print(f\"NLL Val (average): {nll_val}\")\n",
    "print(f\"NLL Test (average): {nll_test}\")\n",
    "print()\n",
    "\n",
    "print(f\"ECE Val (average): {ece_val}\")\n",
    "print(f\"ECE Test (average): {ece_test}\")\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b34874be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC CNN Val: 0.9919948079561042  and  AUC NB Val: 0.828166755829904\n"
     ]
    }
   ],
   "source": [
    "# Weighted Average using AUC (macro one vs rest) - Eq 7 from the paper\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_cnn = roc_auc_score(y_true_val, cnn_probs_val, multi_class=\"ovr\", average='macro')\n",
    "auc_nb = roc_auc_score(y_true_val, nb_probs_val, multi_class=\"ovr\", average='macro')\n",
    "\n",
    "print(f\"AUC CNN Val: {auc_cnn}  and  AUC NB Val: {auc_nb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "505a45f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eta (weights) for CNN: 0.9996241395736278 and NB: 0.9919630255627921\n"
     ]
    }
   ],
   "source": [
    "# Calculate eta (Eq 7)\n",
    "# μ is the average of (1 − AUCc) over the C classifiers\n",
    "m = (1-auc_cnn)+(1-auc_nb)/2\n",
    "eta_cnn_unnorm = np.exp(-(1-auc_cnn)/2*m)\n",
    "eta_nb_unnorm = np.exp(-(1-auc_nb)/2*m)\n",
    "\n",
    "# Z normalizes {ηc}Cc=1 to sum to 1\n",
    "Z = eta_cnn_unnorm + eta_nb_unnorm\n",
    "\n",
    "eta_cnn = eta_cnn_unnorm/Z\n",
    "eta_nb = eta_nb_unnorm/Z\n",
    "\n",
    "print(f\"Eta (weights) for CNN: {eta_cnn_unnorm} and NB: {eta_nb_unnorm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6da8812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the weights to calculate a new wgt avg and pick the highest \n",
    "wgt_avg_probs_val = eta_cnn * cnn_probs_val + eta_nb * nb_probs_val\n",
    "wgt_avg_preds_val = np.argmax(wgt_avg_probs_val, axis=1)\n",
    "\n",
    "wgt_avg_probs_test = eta_cnn * cnn_probs_test + eta_nb * nb_probs_test\n",
    "wgt_avg_preds_test = np.argmax(wgt_avg_probs_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a67d829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Calculate the metrics for wgt_val\n",
    "acc_wgt_avg_val = (wgt_avg_preds_val == y_true_val).mean() * 100\n",
    "nll_wgt_avg_val = log_loss(y_true_val, wgt_avg_probs_val, labels=np.arange(10))\n",
    "ece_wgt_avg_val = ece_score(wgt_avg_probs_val, y_true_val)\n",
    "\n",
    "# Calculate the metrics for wgt_test\n",
    "acc_wgt_avg_test = (wgt_avg_preds_test == y_true_test).mean() * 100\n",
    "nll_wgt_avg_test = log_loss(y_true_test, wgt_avg_probs_test, labels=np.arange(10))\n",
    "ece_wgt_avg_test = ece_score(wgt_avg_probs_test, y_true_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97804806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test (Weighted Average): 74.42%\n",
      "Accuracy Val (Weighted Average): 74.05555555555556%\n",
      "\n",
      "NLL Val (Weighted Average): 0.47311526051460695\n",
      "NLL Test (Weighted Average): 0.4603667767382166\n",
      "\n",
      "ECE Val (Weighted Average): 0.08524692050557625\n",
      "ECE Test (Weighted Average): 0.08735680565192584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All results for simple average (50/50)\n",
    "\n",
    "print(f\"Accuracy Test (Weighted Average): {acc_wgt_avg_test}%\")\n",
    "print(f\"Accuracy Val (Weighted Average): {acc_wgt_avg_val}%\")\n",
    "print()\n",
    "\n",
    "print(f\"NLL Val (Weighted Average): {nll_wgt_avg_val}\")\n",
    "print(f\"NLL Test (Weighted Average): {nll_wgt_avg_test}\")\n",
    "print()\n",
    "\n",
    "print(f\"ECE Val (Weighted Average): {ece_wgt_avg_val}\")\n",
    "print(f\"ECE Test (Weighted Average): {ece_wgt_avg_test}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f6db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Isotonic Calibration Model (MIC)\n",
    "\n",
    "#  MIC constraints (soft voting) Eq 2 (paper)\n",
    "\n",
    "# DAG Eq 3 (paper) ?? tree ordering?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a740a483",
   "metadata": {},
   "source": [
    "2. Applying probability calibration to ensemble methods to predict 2-year mortality in patients with DLBCL\n",
    "Shuanglong Fan, Zhiqiang Zhao, Hongmei Yu, Lei Wang, Chuchu Zheng, Xueqian Huang,\n",
    "Zhenhuan Yang, Meng Xing, Qing Lu and Yanhong Luo\n",
    "\n",
    "The third part is the combination of the base models. We used three methods (simple averaging, weighted averaging, and stacking) to combine the above 5 base models. Stacking or stacked generalization, which takes the outputs of the base models as its inputs, uses another machine learning algorithm (also called a meta-learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb30d914",
   "metadata": {},
   "source": [
    " https://www.analyticsvidhya.com/blog/2021/08/ensemble-stacking-for-machine-learning-and-deep-learning/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb0b70b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def stacking_multinomial_from_frames(cnn_val_df, nb_val_df, cnn_test_df, nb_test_df):\n",
    "\n",
    "    # Merge the two prediction files\n",
    "    val_merged = cnn_val_df.merge(nb_val_df, on=\"id\", suffixes=(\"_cnn\", \"_nb\"))\n",
    "    test_merged = cnn_test_df.merge(nb_test_df, on=\"id\", suffixes=(\"_cnn\", \"_nb\"))\n",
    "\n",
    "    n_classes = 10  \n",
    "\n",
    "    # Get the probability columns per class\n",
    "    cnn_cols = [f\"cnn_class_{i}\" for i in range(n_classes)]\n",
    "    nb_cols  = [f\"nb_class_{i}\"  for i in range(n_classes)]\n",
    "\n",
    "    # Get the probability values per class\n",
    "    cnn_val = val_merged[cnn_cols].values\n",
    "    nb_val  = val_merged[nb_cols].values\n",
    "    y_val   = val_merged[\"true_label_cnn\"].values  \n",
    "\n",
    "    cnn_test = test_merged[cnn_cols].values\n",
    "    nb_test  = test_merged[nb_cols].values\n",
    "    y_test   = test_merged[\"true_label_cnn\"].values\n",
    "\n",
    "    # Create the hstack table that will be needed for the regression \n",
    "    x_val  = np.hstack([cnn_val, nb_val])\n",
    "    x_test = np.hstack([cnn_test, nb_test])\n",
    "\n",
    "    # Train multinomial logistic regression\n",
    "    stacker = LogisticRegression(\n",
    "        multi_class=\"multinomial\",\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=1000\n",
    "    )\n",
    "    stacker.fit(x_val, y_val)\n",
    "\n",
    "    # Get the predicted & calibrated probs \n",
    "    stacked_val  = stacker.predict_proba(x_val)\n",
    "    stacked_test = stacker.predict_proba(x_test)\n",
    "\n",
    "    return stacked_val, stacked_test, y_val, y_test, stacker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02990914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Perform stacking \n",
    "stack_val, stack_test, y_val, y_test, stack_model = stacking_multinomial_from_frames(\n",
    "    cnn_preds_val, nb_preds_val,\n",
    "    cnn_preds_test, nb_preds_test)\n",
    "\n",
    "# Calculate metrics for validation \n",
    "acc_stack_val = (np.argmax(stack_val, axis=1) == y_val).mean() * 100\n",
    "nll_stack_val = log_loss(y_val, stack_val, labels=np.arange(stack_val.shape[1]))\n",
    "ece_stack_val = ece_score(stack_val, y_val)\n",
    "\n",
    "# Calculate metrics for testing  \n",
    "acc_stack_test = (np.argmax(stack_test, axis=1) == y_test).mean() * 100\n",
    "nll_stack_test = log_loss(y_test, stack_test, labels=np.arange(stack_test.shape[1]))\n",
    "ece_stack_test = ece_score(stack_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe8d134c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test (Stacking): 89.84%\n",
      "Accuracy Val (Stacking): 89.92222222222223%\n",
      "\n",
      "NLL Val (Stacking): 0.30949097078855\n",
      "NLL Test (Stacking): 0.3100217280631483\n",
      "\n",
      "ECE Val (Stacking): 0.019311135132109285\n",
      "ECE Test (Stacking): 0.0193937478421264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All results for calibration using stacking (meta-learner)\n",
    "\n",
    "print(f\"Accuracy Test (Stacking): {acc_stack_test}%\")\n",
    "print(f\"Accuracy Val (Stacking): {acc_stack_val}%\")\n",
    "print()\n",
    "\n",
    "print(f\"NLL Val (Stacking): {nll_stack_val}\")\n",
    "print(f\"NLL Test (Stacking): {nll_stack_test}\")\n",
    "print()\n",
    "\n",
    "print(f\"ECE Val (Stacking): {ece_stack_val}\")\n",
    "print(f\"ECE Test (Stacking): {ece_stack_test}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0788f9e9",
   "metadata": {},
   "source": [
    "## Model Comparison – Fashion MNIST (CNN + Naive Bayes)\n",
    "\n",
    "- CNN Accuracy on Test set: 89.88%\n",
    "- NB Accuracy on Test set: 66.80%\n",
    "\n",
    "### Accuracy Results\n",
    "\n",
    "| Method               | Accuracy (Validation) | Accuracy (Test) |\n",
    "|---------------------|---------------------|----------------|\n",
    "| Average             | **66.01%**          | **66.80%**     |\n",
    "| Weighted Average    | **74.06%**          | **74.42%**     |\n",
    "| Stacking            | **89.92%**          | **89.84%**     |\n",
    "\n",
    "\n",
    "\n",
    "### NLL and ECE Results\n",
    "\n",
    "| Method               | NLL (Validation) | NLL (Test) | ECE (Validation) | ECE (Test) |\n",
    "|---------------------|----------------|-----------|----------------|-----------|\n",
    "| Average             | 0.474         | 0.461    | 0.166         | 0.164    |\n",
    "| Weighted Average    | 0.473         | 0.460    | 0.085         | 0.087    |\n",
    "| Stacking            | 0.309         | 0.310    | 0.019         | 0.019    |\n",
    "\n",
    "\n",
    "Stacking achieves the best results with the highest accuracy and lowest NLL/ECE (accurate and well-calibrated).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4f8e5e",
   "metadata": {},
   "source": [
    "3. check bayesian calibration using gaussian process\n",
    "https://discourse.pymc.io/t/bayesian-model-calibration-with-gaussian-process/948"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
