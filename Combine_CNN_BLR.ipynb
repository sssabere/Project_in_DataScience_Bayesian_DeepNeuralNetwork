{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "388ee53b",
   "metadata": {},
   "source": [
    "## Combine CNNs and Naive Bayes predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d2d9338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f34701bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout or full image \n",
    "USE_DROPOUT = True \n",
    "\n",
    "if not USE_DROPOUT:\n",
    "    # CNN (calibrated) on combination splits\n",
    "    CNN_TEST_PATH = \"/Users/ioannaioannidou/Desktop/Uppsala University/Year 2/Semester 1/Project in DS/cnn_comb_test_calibrated_predictions.csv\"\n",
    "    CNN_VAL_PATH  = \"/Users/ioannaioannidou/Desktop/Uppsala University/Year 2/Semester 1/Project in DS/cnn_comb_train_calibrated_predictions.csv\"\n",
    "    # BLR (no calibration) on combination splits\n",
    "    NB_TEST_PATH  = \"/Users/ioannaioannidou/Desktop/Uppsala University/Year 2/Semester 1/Project in DS/blr_full_comb_test_predictions.csv\"\n",
    "    NB_VAL_PATH   = \"/Users/ioannaioannidou/Desktop/Uppsala University/Year 2/Semester 1/Project in DS/blr_full_comb_train_predictions.csv\"\n",
    "else:\n",
    "    CNN_TEST_PATH = \"/Users/ioannaioannidou/Desktop/Uppsala University/Year 2/Semester 1/Project in DS/cnn_dropout_comb_test_calibrated_predictions.csv\"\n",
    "    CNN_VAL_PATH  = \"/Users/ioannaioannidou/Desktop/Uppsala University/Year 2/Semester 1/Project in DS/cnn_dropout_comb_train_calibrated_predictions.csv\"\n",
    "    NB_TEST_PATH  = \"/Users/ioannaioannidou/Desktop/Uppsala University/Year 2/Semester 1/Project in DS/blr_dropout_comb_test_predictions.csv\"\n",
    "    NB_VAL_PATH   = \"/Users/ioannaioannidou/Desktop/Uppsala University/Year 2/Semester 1/Project in DS/blr_dropout_comb_train_predictions.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dfc379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise dfs so merging will be easier \n",
    "def standardise_df(df, want_prefix, current_true_label_col=None):\n",
    "    df = df.copy()\n",
    "    # id column \n",
    "    if \"id\" not in df.columns:\n",
    "        df.insert(0, \"id\", np.arange(len(df)))\n",
    "\n",
    "    # true_label column\n",
    "    if \"true_label\" not in df.columns:\n",
    "        cand = current_true_label_col if current_true_label_col else (\"label\" if \"label\" in df.columns else None)\n",
    "        if cand is not None:\n",
    "            df = df.rename(columns={cand: \"true_label\"})\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # find prob columns \n",
    "    prob_cols = [c for c in df.columns if \"_class_\" in c]\n",
    "    def _cls_idx(c):\n",
    "        try:\n",
    "            return int(c.split(\"_\")[-1])\n",
    "        except:\n",
    "            return 0\n",
    "    prob_cols = sorted(prob_cols, key=_cls_idx)\n",
    "\n",
    "    # rename to the expected prefix \n",
    "    rename_map = {c: f\"{want_prefix}_class_{_cls_idx(c)}\" for c in prob_cols}\n",
    "    df = df.rename(columns=rename_map)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dce1e4",
   "metadata": {},
   "source": [
    "1. Accurate Probability Calibration for Multiple Classifiers by Leon Wenliang Zhong and James T. Kwok\n",
    "\n",
    "In their paper they use soft voting (averaging the probabilities) to get an ensemble starting point for each class. Then they fit an isotonic regression to make the combined probability well-calibrated and finally optimise using alternating direction method of multipliers (ADMM). \n",
    "\n",
    "I will try to replicate their method and see if it improves the accuracy. (exact steps on the paper page 1942)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "658d0828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "4795    1.0\n",
      "4796    1.0\n",
      "4797    1.0\n",
      "4798    1.0\n",
      "4799    1.0\n",
      "Length: 4800, dtype: float64\n",
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "4795    1.0\n",
      "4796    1.0\n",
      "4797    1.0\n",
      "4798    1.0\n",
      "4799    1.0\n",
      "Length: 4800, dtype: float64\n",
      "Accuracy Test (average): 81.97916666666667%\n"
     ]
    }
   ],
   "source": [
    "# TEST DAATASET \n",
    "# Calibrated preds of cnn \n",
    "cnn_preds_test = pd.read_csv(CNN_TEST_PATH)\n",
    "# standardize CNN columns to cnn_class_k + ensure id/true_label exist\n",
    "cnn_preds_test = standardise_df(cnn_preds_test, want_prefix=\"cnn\")\n",
    "\n",
    "cnn_preds_test.head()\n",
    "\n",
    "# The predictions for the Naive Bayes classifier are currently not calibrated - I use it as is just to test my part. \n",
    "# Once we have the calibrated preds we can change them.\n",
    "nb_preds_test = pd.read_csv(NB_TEST_PATH)\n",
    "\n",
    "# BLR files usually have 'label' and no 'id'\n",
    "nb_preds_test = standardise_df(nb_preds_test, want_prefix=\"nb\")\n",
    "nb_preds_test.head()\n",
    "\n",
    "# Merge the two datasets\n",
    "cnn_nb_combined_test = cnn_preds_test.merge(nb_preds_test, on=\"id\")\n",
    "\n",
    "# Get the probs for the CNN and NB\n",
    "cnn_probs_test = cnn_nb_combined_test[[f\"cnn_class_{i}\" for i in range(10)]].values\n",
    "nb_probs_test  = cnn_nb_combined_test[[f\"nb_class_{i}\"  for i in range(10)]].values\n",
    "\n",
    "# Sanity checks \n",
    "# Check if probs sum to 1 for the CNN and NB\n",
    "cnn_sum = cnn_nb_combined_test[[f\"cnn_class_{i}\" for i in range(10)]].sum(axis=1)\n",
    "print(cnn_sum)\n",
    "\n",
    "nb_sum = cnn_nb_combined_test[[f\"nb_class_{i}\" for i in range(10)]].sum(axis=1)\n",
    "print(nb_sum)\n",
    "\n",
    "# Calculate the average prob between CNN and NB \n",
    "avg_probs_test = 0.5 * cnn_probs_test + 0.5 * nb_probs_test\n",
    "\n",
    "# Get the highest (final prediction)\n",
    "avg_preds_test = np.argmax(avg_probs_test, axis=1)\n",
    "# both frames have 'true_label' \n",
    "y_true_test = cnn_nb_combined_test[\"true_label_y\"].values\n",
    "\n",
    "# Get the accuracy \n",
    "accuracy = (avg_preds_test == y_true_test).mean() * 100\n",
    "print(f\"Accuracy Test (average): {accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9c3a7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Val (average): 82.359375%\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION DATASET\n",
    "# Validation preds of CNN and NB\n",
    "cnn_preds_val = pd.read_csv(CNN_VAL_PATH)\n",
    "cnn_preds_val = standardise_df(cnn_preds_val, want_prefix=\"cnn\")\n",
    "cnn_preds_val.head()\n",
    "\n",
    "nb_preds_val = pd.read_csv(NB_VAL_PATH)\n",
    "nb_preds_val = standardise_df(nb_preds_val, want_prefix=\"nb\")\n",
    "nb_preds_val.head()\n",
    "\n",
    "# Merge the two datasets \n",
    "cnn_nb_combined_val = cnn_preds_val.merge(nb_preds_val, on=\"id\")\n",
    "\n",
    "# Get the probs for the CNN and NB\n",
    "cnn_probs_val = cnn_nb_combined_val[[f\"cnn_class_{i}\" for i in range(10)]].values\n",
    "nb_probs_val  = cnn_nb_combined_val[[f\"nb_class_{i}\"  for i in range(10)]].values\n",
    "\n",
    "y_true_val = cnn_nb_combined_val[\"true_label_y\"].values\n",
    "\n",
    "# Repeat for validation\n",
    "avg_probs_val = 0.5 * cnn_probs_val + 0.5 * nb_probs_val\n",
    "avg_preds_val = np.argmax(avg_probs_val, axis=1)\n",
    "\n",
    "accuracy_val = (avg_preds_val == y_true_val).mean() * 100\n",
    "print(f\"Accuracy Val (average): {accuracy_val}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8c3d7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL Val (average): 0.5498834077136138\n",
      "NLL Test (average): 0.5515493621529449\n",
      "ECE Val (average): 0.11573917825881024\n",
      "ECE Test (average): 0.11386967372517837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ioannaioannidou/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:259: UserWarning: The y_prob values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "/Users/ioannaioannidou/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:259: UserWarning: The y_prob values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Calculate NLL and ECE for validation and testing set \n",
    "nll_val = log_loss(y_true_val, avg_probs_val, labels=np.arange(10))\n",
    "print(f\"NLL Val (average): {nll_val}\")\n",
    "\n",
    "nll_test = log_loss(y_true_test, avg_probs_test, labels=np.arange(10))\n",
    "print(f\"NLL Test (average): {nll_test}\")\n",
    "\n",
    "\n",
    "def ece_score(probs, labels, n_bins=15):\n",
    "    confidences = probs.max(axis=1)\n",
    "    predictions = probs.argmax(axis=1)\n",
    "    accuracies = (predictions == labels)\n",
    "\n",
    "    bins = np.linspace(0, 1, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        mask = (confidences > bins[i]) & (confidences <= bins[i+1])\n",
    "        if mask.any():\n",
    "            bin_acc = accuracies[mask].mean()\n",
    "            bin_conf = confidences[mask].mean()\n",
    "            ece += np.abs(bin_acc - bin_conf) * mask.mean()\n",
    "    return ece\n",
    "\n",
    "ece_val = ece_score(avg_probs_val, y_true_val)\n",
    "print(f\"ECE Val (average): {ece_val}\")\n",
    "\n",
    "ece_test = ece_score(avg_probs_test, y_true_test)\n",
    "print(f\"ECE Test (average): {ece_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b84ec05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test (average): 81.97916666666667%\n",
      "Accuracy Val (average): 82.359375%\n",
      "\n",
      "NLL Val (average): 0.5498834077136138\n",
      "NLL Test (average): 0.5515493621529449\n",
      "\n",
      "ECE Val (average): 0.11573917825881024\n",
      "ECE Test (average): 0.11386967372517837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All results for simple average (50/50)\n",
    "print(f\"Accuracy Test (average): {accuracy}%\")\n",
    "print(f\"Accuracy Val (average): {accuracy_val}%\")\n",
    "print()\n",
    "print(f\"NLL Val (average): {nll_val}\")\n",
    "print(f\"NLL Test (average): {nll_test}\")\n",
    "print()\n",
    "print(f\"ECE Val (average): {ece_val}\")\n",
    "print(f\"ECE Test (average): {ece_test}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f73966b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC CNN Val: 0.9810783683244964  and  AUC NB Val: 0.9486706081732063\n",
      "Eta (weights) for CNN: 0.6133257779143674 and NB: 0.38667422208563257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ioannaioannidou/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:259: UserWarning: The y_prob values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "/Users/ioannaioannidou/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:259: UserWarning: The y_prob values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Weighted Average using AUC (macro one-vs-rest) - Eq 7 from the paper \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_cnn = roc_auc_score(y_true_val, cnn_probs_val, multi_class=\"ovr\", average='macro')\n",
    "auc_nb  = roc_auc_score(y_true_val, nb_probs_val,  multi_class=\"ovr\", average='macro')\n",
    "\n",
    "print(f\"AUC CNN Val: {auc_cnn}  and  AUC NB Val: {auc_nb}\")\n",
    "\n",
    "# Calculate eta (Eq 7)\n",
    "# μ is the average of (1 − AUCc) over the C classifiers\n",
    "# (fixed the parenthesis bug so it's truly an average)\n",
    "m = ((1 - auc_cnn) + (1 - auc_nb)) / 2.0\n",
    "\n",
    "# η_c ∝ exp( - (1 - AUC_c) / (2 μ) )  → then normalize to sum to 1\n",
    "eta_cnn_unnorm = np.exp(-(1 - auc_cnn) / (2.0 * m))\n",
    "eta_nb_unnorm  = np.exp(-(1 - auc_nb)  / (2.0 * m))\n",
    "\n",
    "# Z normalizes {ηc}Cc=1 to sum to 1\n",
    "Z = eta_cnn_unnorm + eta_nb_unnorm\n",
    "\n",
    "eta_cnn = eta_cnn_unnorm / Z\n",
    "eta_nb  = eta_nb_unnorm  / Z\n",
    "\n",
    "print(f\"Eta (weights) for CNN: {eta_cnn} and NB: {eta_nb}\")\n",
    "\n",
    "# Use the weights to calculate a new wgt avg and pick the highest \n",
    "wgt_avg_probs_val  = eta_cnn * cnn_probs_val + eta_nb * nb_probs_val\n",
    "wgt_avg_preds_val  = np.argmax(wgt_avg_probs_val, axis=1)\n",
    "\n",
    "wgt_avg_probs_test = eta_cnn * cnn_probs_test + eta_nb * nb_probs_test\n",
    "wgt_avg_preds_test = np.argmax(wgt_avg_probs_test, axis=1)\n",
    "\n",
    "# Calculate the metrics for wgt_val\n",
    "acc_wgt_avg_val  = (wgt_avg_preds_val  == y_true_val).mean() * 100\n",
    "nll_wgt_avg_val  = log_loss(y_true_val,  wgt_avg_probs_val,  labels=np.arange(10))\n",
    "ece_wgt_avg_val  = ece_score(wgt_avg_probs_val,  y_true_val)\n",
    "\n",
    "# Calculate the metrics for wgt_test\n",
    "acc_wgt_avg_test = (wgt_avg_preds_test == y_true_test).mean() * 100\n",
    "nll_wgt_avg_test = log_loss(y_true_test, wgt_avg_probs_test, labels=np.arange(10))\n",
    "ece_wgt_avg_test = ece_score(wgt_avg_probs_test, y_true_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14bd68d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test (Weighted Average): 81.95833333333333%\n",
      "Accuracy Val (Weighted Average): 82.328125%\n",
      "\n",
      "NLL Val (Weighted Average): 0.5215816772425292\n",
      "NLL Test (Weighted Average): 0.5227144528971687\n",
      "\n",
      "ECE Val (Weighted Average): 0.08237789081689495\n",
      "ECE Test (Weighted Average): 0.08091613027857282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All results for weighted average\n",
    "print(f\"Accuracy Test (Weighted Average): {acc_wgt_avg_test}%\")\n",
    "print(f\"Accuracy Val (Weighted Average): {acc_wgt_avg_val}%\")\n",
    "print()\n",
    "print(f\"NLL Val (Weighted Average): {nll_wgt_avg_val}\")\n",
    "print(f\"NLL Test (Weighted Average): {nll_wgt_avg_test}\")\n",
    "print()\n",
    "print(f\"ECE Val (Weighted Average): {ece_wgt_avg_val}\")\n",
    "print(f\"ECE Test (Weighted Average): {ece_wgt_avg_test}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b17aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Isotonic Calibration Model (MIC)\n",
    "\n",
    "#  MIC constraints (soft voting) Eq 2 (paper)\n",
    "\n",
    "# DAG Eq 3 (paper) ?? tree ordering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ecd688",
   "metadata": {},
   "source": [
    "2. Applying probability calibration to ensemble methods to predict 2-year mortality in patients with DLBCL\n",
    "Shuanglong Fan, Zhiqiang Zhao, Hongmei Yu, Lei Wang, Chuchu Zheng, Xueqian Huang,\n",
    "Zhenhuan Yang, Meng Xing, Qing Lu and Yanhong Luo\n",
    "\n",
    "The third part is the combination of the base models. We used three methods (simple averaging, weighted averaging, and stacking) to combine the above 5 base models. Stacking or stacked generalization, which takes the outputs of the base models as its inputs, uses another machine learning algorithm (also called a meta-learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1217059c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ioannaioannidou/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Stacking meta-learner\n",
    "def stacking_multinomial_from_frames(cnn_val_df, nb_val_df, cnn_test_df, nb_test_df):\n",
    "\n",
    "    # Merge the two prediction files\n",
    "    val_merged = cnn_val_df.merge(nb_val_df, on=\"id\", suffixes=(\"_cnn\", \"_nb\"))\n",
    "    test_merged = cnn_test_df.merge(nb_test_df, on=\"id\", suffixes=(\"_cnn\", \"_nb\"))\n",
    "\n",
    "    n_classes = 10  \n",
    "\n",
    "    # Get the probability columns per class\n",
    "    cnn_cols = [f\"cnn_class_{i}\" for i in range(n_classes)]\n",
    "    nb_cols  = [f\"nb_class_{i}\"  for i in range(n_classes)]\n",
    "\n",
    "    # Get the probability values per class\n",
    "    cnn_val = val_merged[cnn_cols].values\n",
    "    nb_val  = val_merged[nb_cols].values\n",
    "    y_val   = val_merged[\"true_label_cnn\"].values  \n",
    "\n",
    "    cnn_test = test_merged[cnn_cols].values\n",
    "    nb_test  = test_merged[nb_cols].values\n",
    "    y_test   = test_merged[\"true_label_cnn\"].values\n",
    "\n",
    "    # Create the hstack table that will be needed for the regression \n",
    "    x_val  = np.hstack([cnn_val, nb_val])\n",
    "    x_test = np.hstack([cnn_test, nb_test])\n",
    "\n",
    "    # Train multinomial logistic regression\n",
    "    stacker = LogisticRegression(\n",
    "        multi_class=\"multinomial\",\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=1000\n",
    "    )\n",
    "    stacker.fit(x_val, y_val)\n",
    "\n",
    "    # Get the predicted & calibrated probs \n",
    "    stacked_val  = stacker.predict_proba(x_val)\n",
    "    stacked_test = stacker.predict_proba(x_test)\n",
    "\n",
    "    return stacked_val, stacked_test, y_val, y_test, stacker\n",
    "\n",
    "# Perform stacking \n",
    "stack_val, stack_test, y_val, y_test, stack_model = stacking_multinomial_from_frames(\n",
    "    cnn_preds_val, nb_preds_val,\n",
    "    cnn_preds_test, nb_preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55db66a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test (Stacking): 84.85416666666666%\n",
      "Accuracy Val (Stacking): 84.8125%\n",
      "\n",
      "NLL Val (Stacking): 0.4141678229236834\n",
      "NLL Test (Stacking): 0.41917520434260797\n",
      "\n",
      "ECE Val (Stacking): 0.008308374090578658\n",
      "ECE Test (Stacking): 0.012554928047833465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for validation \n",
    "acc_stack_val = (np.argmax(stack_val, axis=1) == y_val).mean() * 100\n",
    "nll_stack_val = log_loss(y_val, stack_val, labels=np.arange(stack_val.shape[1]))\n",
    "ece_stack_val = ece_score(stack_val, y_val)\n",
    "\n",
    "# Calculate metrics for testing  \n",
    "acc_stack_test = (np.argmax(stack_test, axis=1) == y_test).mean() * 100\n",
    "nll_stack_test = log_loss(y_test, stack_test, labels=np.arange(stack_test.shape[1]))\n",
    "ece_stack_test = ece_score(stack_test, y_test)\n",
    "\n",
    "# All results for calibration using stacking (meta-learner)\n",
    "print(f\"Accuracy Test (Stacking): {acc_stack_test}%\")\n",
    "print(f\"Accuracy Val (Stacking): {acc_stack_val}%\")\n",
    "print()\n",
    "print(f\"NLL Val (Stacking): {nll_stack_val}\")\n",
    "print(f\"NLL Test (Stacking): {nll_stack_test}\")\n",
    "print()\n",
    "print(f\"ECE Val (Stacking): {ece_stack_val}\")\n",
    "print(f\"ECE Test (Stacking): {ece_stack_test}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574ac1ae",
   "metadata": {},
   "source": [
    "# SUMMARY FULL IMAGE\n",
    "\n",
    "### Full Images – Combination Results\n",
    "\n",
    "| Method                            | Accuracy (Val) | Accuracy (Test) | NLL (Val) | NLL (Test) | ECE (Val) | ECE (Test) |\n",
    "|----------------------------------|----------------|-----------------|------------|-------------|------------|-------------|\n",
    "| **Simple Average (50/50)**       | 88.42%         | 88.58%          | 0.4876     | 0.4833      | 0.1781     | 0.1789      |\n",
    "| **Weighted Average (AUC-based)** | 88.46%         | 88.50%          | 0.4169     | 0.4131      | 0.1209     | 0.1206      |\n",
    "| **Stacking (Meta-Model)**        | 88.94%         | 88.19%          | 0.3213     | 0.3333      | 0.0138     | 0.0197      |\n",
    "\n",
    "Stacking achieves lowest ECE and NLL, while accuracy differences are minimal across methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc0efdd",
   "metadata": {},
   "source": [
    "# SUMMARY DROPOUT IMAGES\n",
    "\n",
    "### Dropout Images – Combination Results\n",
    "\n",
    "| Method                            | Accuracy (Val) | Accuracy (Test) | NLL (Val) | NLL (Test) | ECE (Val) | ECE (Test) |\n",
    "|----------------------------------|----------------|-----------------|------------|-------------|------------|-------------|\n",
    "| **Simple Average (50/50)**       | 82.36%         | 81.98%          | 0.5499     | 0.5515      | 0.1157     | 0.1139      |\n",
    "| **Weighted Average (AUC-based)** | 82.33%         | 81.96%          | 0.5216     | 0.5227      | 0.0824     | 0.0809      |\n",
    "| **Stacking (Meta-Model)**        | 84.81%         | 84.85%          | 0.4142     | 0.4192      | 0.0083     | 0.0126      |\n",
    "\n",
    " Stacking again achieves the best performance, significantly improving both accuracy and ECE compared to averaging methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e6509e",
   "metadata": {},
   "source": [
    "# Train several meta learners \n",
    "Important to mention that i combined the predictions of CNN and BLR for both full and drop out images and all these 4 columns for 10 classes will be the 40 features that will be used to train a new meta learner. \n",
    "\n",
    "- A static one (Logistic Regression) that will learn the weights for each model and whether is a full or drop out images and apply it to make new predicions\n",
    "\n",
    "- A dynamic one (Random Forest and Gradient Boosting) that will learn to adjust the weights based on the patterns observed in the input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27403551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bb8fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv files containing the predictions\n",
    "def load_preds(path, prefix):\n",
    "    df = pd.read_csv(path).copy()\n",
    "    if \"true_label\" not in df.columns and \"label\" in df.columns:\n",
    "        df = df.rename(columns={\"label\": \"true_label\"})\n",
    "    prob_cols = [c for c in df.columns if \"_class_\" in c]\n",
    "    for c in prob_cols:\n",
    "        idx = c.split(\"_\")[-1]\n",
    "        df = df.rename(columns={c: f\"{prefix}_class_{idx}\"})\n",
    "    if \"id\" not in df.columns:\n",
    "        df.insert(0, \"id\", np.arange(len(df)))\n",
    "    return df\n",
    "\n",
    "cnn_full_train = load_preds(\"cnn_comb_train_calibrated_predictions.csv\", \"cnn_full\")\n",
    "cnn_full_test  = load_preds(\"cnn_comb_test_calibrated_predictions.csv\", \"cnn_full\")\n",
    "\n",
    "cnn_drop_train = load_preds(\"cnn_dropout_comb_train_calibrated_predictions.csv\", \"cnn_drop\")\n",
    "cnn_drop_test  = load_preds(\"cnn_dropout_comb_test_calibrated_predictions.csv\", \"cnn_drop\")\n",
    "\n",
    "blr_full_train = load_preds(\"blr_full_comb_train_predictions.csv\", \"blr_full\")\n",
    "blr_full_test  = load_preds(\"blr_full_comb_test_predictions.csv\", \"blr_full\")\n",
    "\n",
    "blr_drop_train = load_preds(\"blr_dropout_comb_train_predictions.csv\", \"blr_drop\")\n",
    "blr_drop_test  = load_preds(\"blr_dropout_comb_test_predictions.csv\", \"blr_drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83c6a37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (19200, 45) Test: (4800, 45)\n"
     ]
    }
   ],
   "source": [
    "# Clean up duplicate true_label columns before merging otherwise python complaints  \n",
    "def drop_extra_labels(df):\n",
    "    cols = [c for c in df.columns if \"true_label\" in c]\n",
    "    if len(cols) > 1:\n",
    "        df = df.drop(columns=cols[1:])\n",
    "    return df\n",
    "\n",
    "cnn_full_train = drop_extra_labels(cnn_full_train)\n",
    "cnn_drop_train = drop_extra_labels(cnn_drop_train)\n",
    "blr_full_train = drop_extra_labels(blr_full_train)\n",
    "blr_drop_train = drop_extra_labels(blr_drop_train)\n",
    "\n",
    "cnn_full_test = drop_extra_labels(cnn_full_test)\n",
    "cnn_drop_test = drop_extra_labels(cnn_drop_test)\n",
    "blr_full_test = drop_extra_labels(blr_full_test)\n",
    "blr_drop_test = drop_extra_labels(blr_drop_test)\n",
    "\n",
    "# Merge datasets on id\n",
    "train_df = (\n",
    "    cnn_full_train\n",
    "    .merge(cnn_drop_train, on=\"id\", suffixes=(\"\", \"_dup1\"))\n",
    "    .merge(blr_full_train, on=\"id\", suffixes=(\"\", \"_dup2\"))\n",
    "    .merge(blr_drop_train, on=\"id\", suffixes=(\"\", \"_dup3\")))\n",
    "\n",
    "test_df = (\n",
    "    cnn_full_test\n",
    "    .merge(cnn_drop_test, on=\"id\", suffixes=(\"\", \"_dup1\"))\n",
    "    .merge(blr_full_test, on=\"id\", suffixes=(\"\", \"_dup2\"))\n",
    "    .merge(blr_drop_test, on=\"id\", suffixes=(\"\", \"_dup3\")))\n",
    "\n",
    "print(\"Train:\", train_df.shape, \"Test:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb9d5980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ioannaioannidou/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split dependent and independent vars \n",
    "feature_cols = [c for c in train_df.columns if \"_class_\" in c]\n",
    "X_train = train_df[feature_cols].values\n",
    "y_train = train_df[\"true_label\"].values \n",
    "X_test  = test_df[feature_cols].values\n",
    "y_test  = test_df[\"true_label\"].values\n",
    "\n",
    "print(\"Features:\", len(feature_cols))\n",
    "\n",
    "# Meta-learners used \n",
    "models = {\n",
    "    \"LogReg\": LogisticRegression(max_iter=1000, multi_class=\"multinomial\"),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=200, max_depth=None, random_state=0),\n",
    "    \"GBM\": GradientBoostingClassifier(n_estimators=300, learning_rate=0.05, max_depth=3, random_state=0)}\n",
    "\n",
    "# Fit, test each of them and evaluate them \n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    probs_val = model.predict_proba(X_train)\n",
    "    probs_test = model.predict_proba(X_test)\n",
    "\n",
    "    acc_val = (np.argmax(probs_val, 1) == y_train).mean() * 100\n",
    "    acc_test = (np.argmax(probs_test, 1) == y_test).mean() * 100\n",
    "    nll_val = log_loss(y_train, probs_val, labels=np.arange(probs_val.shape[1]))\n",
    "    nll_test = log_loss(y_test, probs_test, labels=np.arange(probs_test.shape[1]))\n",
    "    ece_val = ece_score(probs_val, y_train)\n",
    "    ece_test = ece_score(probs_test, y_test)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy (Val)\": acc_val,\n",
    "        \"Accuracy (Test)\": acc_test,\n",
    "        \"NLL (Val)\": nll_val,\n",
    "        \"NLL (Test)\": nll_test,\n",
    "        \"ECE (Val)\": ece_val,\n",
    "        \"ECE (Test)\": ece_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ec5f749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d9219\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d9219_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_d9219_level0_col1\" class=\"col_heading level0 col1\" >Accuracy (Val)</th>\n",
       "      <th id=\"T_d9219_level0_col2\" class=\"col_heading level0 col2\" >Accuracy (Test)</th>\n",
       "      <th id=\"T_d9219_level0_col3\" class=\"col_heading level0 col3\" >NLL (Val)</th>\n",
       "      <th id=\"T_d9219_level0_col4\" class=\"col_heading level0 col4\" >NLL (Test)</th>\n",
       "      <th id=\"T_d9219_level0_col5\" class=\"col_heading level0 col5\" >ECE (Val)</th>\n",
       "      <th id=\"T_d9219_level0_col6\" class=\"col_heading level0 col6\" >ECE (Test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d9219_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d9219_row0_col0\" class=\"data row0 col0\" >LogReg</td>\n",
       "      <td id=\"T_d9219_row0_col1\" class=\"data row0 col1\" >89.57%</td>\n",
       "      <td id=\"T_d9219_row0_col2\" class=\"data row0 col2\" >89.02%</td>\n",
       "      <td id=\"T_d9219_row0_col3\" class=\"data row0 col3\" >0.2990</td>\n",
       "      <td id=\"T_d9219_row0_col4\" class=\"data row0 col4\" >0.3116</td>\n",
       "      <td id=\"T_d9219_row0_col5\" class=\"data row0 col5\" >0.0128</td>\n",
       "      <td id=\"T_d9219_row0_col6\" class=\"data row0 col6\" >0.0142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9219_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d9219_row1_col0\" class=\"data row1 col0\" >RF</td>\n",
       "      <td id=\"T_d9219_row1_col1\" class=\"data row1 col1\" >100.00%</td>\n",
       "      <td id=\"T_d9219_row1_col2\" class=\"data row1 col2\" >89.27%</td>\n",
       "      <td id=\"T_d9219_row1_col3\" class=\"data row1 col3\" >0.0686</td>\n",
       "      <td id=\"T_d9219_row1_col4\" class=\"data row1 col4\" >0.3434</td>\n",
       "      <td id=\"T_d9219_row1_col5\" class=\"data row1 col5\" >0.0607</td>\n",
       "      <td id=\"T_d9219_row1_col6\" class=\"data row1 col6\" >0.0169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9219_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d9219_row2_col0\" class=\"data row2 col0\" >GBM</td>\n",
       "      <td id=\"T_d9219_row2_col1\" class=\"data row2 col1\" >95.17%</td>\n",
       "      <td id=\"T_d9219_row2_col2\" class=\"data row2 col2\" >88.90%</td>\n",
       "      <td id=\"T_d9219_row2_col3\" class=\"data row2 col3\" >0.1493</td>\n",
       "      <td id=\"T_d9219_row2_col4\" class=\"data row2 col4\" >0.3128</td>\n",
       "      <td id=\"T_d9219_row2_col5\" class=\"data row2 col5\" >0.0351</td>\n",
       "      <td id=\"T_d9219_row2_col6\" class=\"data row2 col6\" >0.0243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x145dee2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary \n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df.style.format({\n",
    "    \"Accuracy (Val)\": \"{:.2f}%\",\n",
    "    \"Accuracy (Test)\": \"{:.2f}%\",\n",
    "    \"NLL (Val)\": \"{:.4f}\",\n",
    "    \"NLL (Test)\": \"{:.4f}\",\n",
    "    \"ECE (Val)\": \"{:.4f}\",\n",
    "    \"ECE (Test)\": \"{:.4f}\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a6cb29",
   "metadata": {},
   "source": [
    "### Meta-Learner (Full & Dropout Images Predictions)\n",
    "\n",
    "| Model | Accuracy (Val) | Accuracy (Test) | NLL (Val) | NLL (Test) | ECE (Val) | ECE (Test) |\n",
    "|--------|----------------|-----------------|------------|-------------|------------|-------------|\n",
    "| **Logistic Regression** | 89.57% | 89.02% | 0.2990 | 0.3116 | 0.0128 | 0.0142 |\n",
    "| **Random Forest**       | 100.00% | 89.27% | 0.0686 | 0.3434 | 0.0607 | 0.0169 |\n",
    "| **Gradient Boosting**   | 95.17% | 88.90% | 0.1493 | 0.3128 | 0.0351 | 0.0243 |\n",
    "\n",
    "\n",
    "- Logistic Regression provides the best generalization (lowest NLL & ECE on both val/test)\n",
    "- Random Forest clearly overfits (100% Val Acc but drop on Test + higher NLL)\n",
    "- Gradient Boosting performs well, slightly under LogReg, showing slight overfitting too \n",
    "\n",
    "Logistic Regression is the best for now (static) for the other nonlinear cases i should optimise them to improve generalisation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
