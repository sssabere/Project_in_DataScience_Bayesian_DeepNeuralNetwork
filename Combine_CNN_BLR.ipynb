{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "388ee53b",
   "metadata": {},
   "source": [
    "## Combine CNNs and Naive Bayes predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d2d9338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f34701bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout or full image \n",
    "USE_DROPOUT = False \n",
    "\n",
    "if not USE_DROPOUT:\n",
    "    # CNN (calibrated) on combination splits\n",
    "    CNN_TEST_PATH = \"/Users/ioannaioannidou/Desktop/Uppsala University/Year 2/Semester 1/Project in DS/cnn_comb_test_calibrated_predictions.csv\"\n",
    "    CNN_VAL_PATH  = \"/Users/ioannaioannidou/Desktop/Uppsala University/Year 2/Semester 1/Project in DS/cnn_comb_train_calibrated_predictions.csv\"\n",
    "    # BLR (no calibration) on combination splits\n",
    "    NB_TEST_PATH  = \"/Users/ioannaioannidou/Desktop/Uppsala University/Year 2/Semester 1/Project in DS/blr_full_comb_test_predictions.csv\"\n",
    "    NB_VAL_PATH   = \"/Users/ioannaioannidou/Desktop/Uppsala University/Year 2/Semester 1/Project in DS/blr_full_comb_train_predictions.csv\"\n",
    "else:\n",
    "    CNN_TEST_PATH = \"/Users/ioannaioannidou/Desktop/Uppsala University/Year 2/Semester 1/Project in DS/cnn_dropout_comb_test_calibrated_predictions.csv\"\n",
    "    CNN_VAL_PATH  = \"/Users/ioannaioannidou/Desktop/Uppsala University/Year 2/Semester 1/Project in DS/cnn_dropout_comb_train_calibrated_predictions.csv\"\n",
    "    NB_TEST_PATH  = \"/Users/ioannaioannidou/Desktop/Uppsala University/Year 2/Semester 1/Project in DS/blr_dropout_comb_test_predictions.csv\"\n",
    "    NB_VAL_PATH   = \"/Users/ioannaioannidou/Desktop/Uppsala University/Year 2/Semester 1/Project in DS/blr_dropout_comb_train_predictions.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7dfc379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise dfs so merging will be easier \n",
    "def standardise_df(df, want_prefix, current_true_label_col=None):\n",
    "    df = df.copy()\n",
    "    # id column \n",
    "    if \"id\" not in df.columns:\n",
    "        df.insert(0, \"id\", np.arange(len(df)))\n",
    "\n",
    "    # true_label column\n",
    "    if \"true_label\" not in df.columns:\n",
    "        cand = current_true_label_col if current_true_label_col else (\"label\" if \"label\" in df.columns else None)\n",
    "        if cand is not None:\n",
    "            df = df.rename(columns={cand: \"true_label\"})\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # find prob columns \n",
    "    prob_cols = [c for c in df.columns if \"_class_\" in c]\n",
    "    def _cls_idx(c):\n",
    "        try:\n",
    "            return int(c.split(\"_\")[-1])\n",
    "        except:\n",
    "            return 0\n",
    "    prob_cols = sorted(prob_cols, key=_cls_idx)\n",
    "\n",
    "    # rename to the expected prefix \n",
    "    rename_map = {c: f\"{want_prefix}_class_{_cls_idx(c)}\" for c in prob_cols}\n",
    "    df = df.rename(columns=rename_map)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dce1e4",
   "metadata": {},
   "source": [
    "1. Accurate Probability Calibration for Multiple Classifiers by Leon Wenliang Zhong and James T. Kwok\n",
    "\n",
    "In their paper they use soft voting (averaging the probabilities) to get an ensemble starting point for each class. Then they fit an isotonic regression to make the combined probability well-calibrated and finally optimise using alternating direction method of multipliers (ADMM). \n",
    "\n",
    "I will try to replicate their method and see if it improves the accuracy. (exact steps on the paper page 1942)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "658d0828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "4795    1.0\n",
      "4796    1.0\n",
      "4797    1.0\n",
      "4798    1.0\n",
      "4799    1.0\n",
      "Length: 4800, dtype: float64\n",
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "4795    1.0\n",
      "4796    1.0\n",
      "4797    1.0\n",
      "4798    1.0\n",
      "4799    1.0\n",
      "Length: 4800, dtype: float64\n",
      "Accuracy Test (average): 89.35416666666667%\n"
     ]
    }
   ],
   "source": [
    "# TEST DATASET \n",
    "# Calibrated preds of cnn \n",
    "cnn_preds_test = pd.read_csv(CNN_TEST_PATH)\n",
    "# standardize CNN columns to cnn_class_k + ensure id/true_label exist\n",
    "cnn_preds_test = standardise_df(cnn_preds_test, want_prefix=\"cnn\")\n",
    "\n",
    "cnn_preds_test.head()\n",
    "\n",
    "# The predictions for the Naive Bayes classifier are currently not calibrated - I use it as is just to test my part. \n",
    "# Once we have the calibrated preds we can change them.\n",
    "nb_preds_test = pd.read_csv(NB_TEST_PATH)\n",
    "\n",
    "# BLR files usually have 'label' and no 'id'\n",
    "nb_preds_test = standardise_df(nb_preds_test, want_prefix=\"nb\")\n",
    "nb_preds_test.head()\n",
    "\n",
    "# Merge the two datasets\n",
    "cnn_nb_combined_test = cnn_preds_test.merge(nb_preds_test, on=\"id\")\n",
    "\n",
    "# Get the probs for the CNN and NB\n",
    "cnn_probs_test = cnn_nb_combined_test[[f\"cnn_class_{i}\" for i in range(10)]].values\n",
    "nb_probs_test  = cnn_nb_combined_test[[f\"nb_class_{i}\"  for i in range(10)]].values\n",
    "\n",
    "# Sanity checks \n",
    "# Check if probs sum to 1 for the CNN and NB\n",
    "cnn_sum = cnn_nb_combined_test[[f\"cnn_class_{i}\" for i in range(10)]].sum(axis=1)\n",
    "print(cnn_sum)\n",
    "\n",
    "nb_sum = cnn_nb_combined_test[[f\"nb_class_{i}\" for i in range(10)]].sum(axis=1)\n",
    "print(nb_sum)\n",
    "\n",
    "# Calculate the average prob between CNN and NB \n",
    "avg_probs_test = 0.5 * cnn_probs_test + 0.5 * nb_probs_test\n",
    "\n",
    "# Get the highest (final prediction)\n",
    "avg_preds_test = np.argmax(avg_probs_test, axis=1)\n",
    "# both frames have 'true_label' \n",
    "y_true_test = cnn_nb_combined_test[\"true_label_y\"].values\n",
    "\n",
    "# Get the accuracy \n",
    "accuracy = (avg_preds_test == y_true_test).mean() * 100\n",
    "print(f\"Accuracy Test (average): {accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9c3a7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Val (average): 89.04166666666666%\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION DATASET\n",
    "# Validation preds of CNN and NB\n",
    "cnn_preds_val = pd.read_csv(CNN_VAL_PATH)\n",
    "cnn_preds_val = standardise_df(cnn_preds_val, want_prefix=\"cnn\")\n",
    "cnn_preds_val.head()\n",
    "\n",
    "nb_preds_val = pd.read_csv(NB_VAL_PATH)\n",
    "nb_preds_val = standardise_df(nb_preds_val, want_prefix=\"nb\")\n",
    "nb_preds_val.head()\n",
    "\n",
    "# Merge the two datasets \n",
    "cnn_nb_combined_val = cnn_preds_val.merge(nb_preds_val, on=\"id\")\n",
    "\n",
    "# Get the probs for the CNN and NB\n",
    "cnn_probs_val = cnn_nb_combined_val[[f\"cnn_class_{i}\" for i in range(10)]].values\n",
    "nb_probs_val  = cnn_nb_combined_val[[f\"nb_class_{i}\"  for i in range(10)]].values\n",
    "\n",
    "y_true_val = cnn_nb_combined_val[\"true_label_y\"].values\n",
    "\n",
    "# Repeat for validation\n",
    "avg_probs_val = 0.5 * cnn_probs_val + 0.5 * nb_probs_val\n",
    "avg_preds_val = np.argmax(avg_probs_val, axis=1)\n",
    "\n",
    "accuracy_val = (avg_preds_val == y_true_val).mean() * 100\n",
    "print(f\"Accuracy Val (average): {accuracy_val}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8c3d7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL Val (average): 0.4818627455555805\n",
      "NLL Test (average): 0.4687900580408005\n",
      "ECE Val (average): 0.17960157582764352\n",
      "ECE Test (average): 0.18347657851176266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ioannaioannidou/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:259: UserWarning: The y_prob values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "/Users/ioannaioannidou/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:259: UserWarning: The y_prob values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Calculate NLL and ECE for validation and testing set \n",
    "nll_val = log_loss(y_true_val, avg_probs_val, labels=np.arange(10))\n",
    "print(f\"NLL Val (average): {nll_val}\")\n",
    "\n",
    "nll_test = log_loss(y_true_test, avg_probs_test, labels=np.arange(10))\n",
    "print(f\"NLL Test (average): {nll_test}\")\n",
    "\n",
    "\n",
    "def ece_score(probs, labels, n_bins=15):\n",
    "    confidences = probs.max(axis=1)\n",
    "    predictions = probs.argmax(axis=1)\n",
    "    accuracies = (predictions == labels)\n",
    "\n",
    "    bins = np.linspace(0, 1, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        mask = (confidences > bins[i]) & (confidences <= bins[i+1])\n",
    "        if mask.any():\n",
    "            bin_acc = accuracies[mask].mean()\n",
    "            bin_conf = confidences[mask].mean()\n",
    "            ece += np.abs(bin_acc - bin_conf) * mask.mean()\n",
    "    return ece\n",
    "\n",
    "ece_val = ece_score(avg_probs_val, y_true_val)\n",
    "print(f\"ECE Val (average): {ece_val}\")\n",
    "\n",
    "ece_test = ece_score(avg_probs_test, y_true_test)\n",
    "print(f\"ECE Test (average): {ece_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b84ec05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test (average): 89.35416666666667%\n",
      "Accuracy Val (average): 89.04166666666666%\n",
      "\n",
      "NLL Val (average): 0.4818627455555805\n",
      "NLL Test (average): 0.4687900580408005\n",
      "\n",
      "ECE Val (average): 0.17960157582764352\n",
      "ECE Test (average): 0.18347657851176266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All results for simple average (50/50)\n",
    "print(f\"Accuracy Test (average): {accuracy}%\")\n",
    "print(f\"Accuracy Val (average): {accuracy_val}%\")\n",
    "print()\n",
    "print(f\"NLL Val (average): {nll_val}\")\n",
    "print(f\"NLL Test (average): {nll_test}\")\n",
    "print()\n",
    "print(f\"ECE Val (average): {ece_val}\")\n",
    "print(f\"ECE Test (average): {ece_test}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f73966b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC CNN Val: 0.9903645917848202  and  AUC NB Val: 0.9439482804073871\n",
      "Eta (weights) for CNN: 0.669655467039116 and NB: 0.33034453296088384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ioannaioannidou/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:259: UserWarning: The y_prob values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "/Users/ioannaioannidou/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:259: UserWarning: The y_prob values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Weighted Average using AUC (macro one-vs-rest) - Eq 7 from the paper \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_cnn = roc_auc_score(y_true_val, cnn_probs_val, multi_class=\"ovr\", average='macro')\n",
    "auc_nb  = roc_auc_score(y_true_val, nb_probs_val,  multi_class=\"ovr\", average='macro')\n",
    "\n",
    "print(f\"AUC CNN Val: {auc_cnn}  and  AUC NB Val: {auc_nb}\")\n",
    "\n",
    "# Calculate eta (Eq 7)\n",
    "# μ is the average of (1 − AUCc) over the C classifiers\n",
    "# (fixed the parenthesis bug so it's truly an average)\n",
    "m = ((1 - auc_cnn) + (1 - auc_nb)) / 2.0\n",
    "\n",
    "# η_c ∝ exp( - (1 - AUC_c) / (2 μ) )  → then normalize to sum to 1\n",
    "eta_cnn_unnorm = np.exp(-(1 - auc_cnn) / (2.0 * m))\n",
    "eta_nb_unnorm  = np.exp(-(1 - auc_nb)  / (2.0 * m))\n",
    "\n",
    "# Z normalizes {ηc}Cc=1 to sum to 1\n",
    "Z = eta_cnn_unnorm + eta_nb_unnorm\n",
    "\n",
    "eta_cnn = eta_cnn_unnorm / Z\n",
    "eta_nb  = eta_nb_unnorm  / Z\n",
    "\n",
    "print(f\"Eta (weights) for CNN: {eta_cnn} and NB: {eta_nb}\")\n",
    "\n",
    "# Use the weights to calculate a new wgt avg and pick the highest \n",
    "wgt_avg_probs_val  = eta_cnn * cnn_probs_val + eta_nb * nb_probs_val\n",
    "wgt_avg_preds_val  = np.argmax(wgt_avg_probs_val, axis=1)\n",
    "\n",
    "wgt_avg_probs_test = eta_cnn * cnn_probs_test + eta_nb * nb_probs_test\n",
    "wgt_avg_preds_test = np.argmax(wgt_avg_probs_test, axis=1)\n",
    "\n",
    "# Calculate the metrics for wgt_val\n",
    "acc_wgt_avg_val  = (wgt_avg_preds_val  == y_true_val).mean() * 100\n",
    "nll_wgt_avg_val  = log_loss(y_true_val,  wgt_avg_probs_val,  labels=np.arange(10))\n",
    "ece_wgt_avg_val  = ece_score(wgt_avg_probs_val,  y_true_val)\n",
    "\n",
    "# Calculate the metrics for wgt_test\n",
    "acc_wgt_avg_test = (wgt_avg_preds_test == y_true_test).mean() * 100\n",
    "nll_wgt_avg_test = log_loss(y_true_test, wgt_avg_probs_test, labels=np.arange(10))\n",
    "ece_wgt_avg_test = ece_score(wgt_avg_probs_test, y_true_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "14bd68d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test (Weighted Average): 89.4375%\n",
      "Accuracy Val (Weighted Average): 89.11458333333333%\n",
      "\n",
      "NLL Val (Weighted Average): 0.4110672363736175\n",
      "NLL Test (Weighted Average): 0.3974945196568485\n",
      "\n",
      "ECE Val (Weighted Average): 0.12101190416971054\n",
      "ECE Test (Weighted Average): 0.12511775757806326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All results for weighted average\n",
    "print(f\"Accuracy Test (Weighted Average): {acc_wgt_avg_test}%\")\n",
    "print(f\"Accuracy Val (Weighted Average): {acc_wgt_avg_val}%\")\n",
    "print()\n",
    "print(f\"NLL Val (Weighted Average): {nll_wgt_avg_val}\")\n",
    "print(f\"NLL Test (Weighted Average): {nll_wgt_avg_test}\")\n",
    "print()\n",
    "print(f\"ECE Val (Weighted Average): {ece_wgt_avg_val}\")\n",
    "print(f\"ECE Test (Weighted Average): {ece_wgt_avg_test}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b17aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Isotonic Calibration Model (MIC)\n",
    "\n",
    "#  MIC constraints (soft voting) Eq 2 (paper)\n",
    "\n",
    "# DAG Eq 3 (paper) ?? tree ordering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ecd688",
   "metadata": {},
   "source": [
    "2. Applying probability calibration to ensemble methods to predict 2-year mortality in patients with DLBCL\n",
    "Shuanglong Fan, Zhiqiang Zhao, Hongmei Yu, Lei Wang, Chuchu Zheng, Xueqian Huang,\n",
    "Zhenhuan Yang, Meng Xing, Qing Lu and Yanhong Luo\n",
    "\n",
    "The third part is the combination of the base models. We used three methods (simple averaging, weighted averaging, and stacking) to combine the above 5 base models. Stacking or stacked generalization, which takes the outputs of the base models as its inputs, uses another machine learning algorithm (also called a meta-learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1217059c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ioannaioannidou/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Stacking meta-learner\n",
    "def stacking_multinomial_from_frames(cnn_val_df, nb_val_df, cnn_test_df, nb_test_df):\n",
    "\n",
    "    # Merge the two prediction files\n",
    "    val_merged = cnn_val_df.merge(nb_val_df, on=\"id\", suffixes=(\"_cnn\", \"_nb\"))\n",
    "    test_merged = cnn_test_df.merge(nb_test_df, on=\"id\", suffixes=(\"_cnn\", \"_nb\"))\n",
    "\n",
    "    n_classes = 10  \n",
    "\n",
    "    # Get the probability columns per class\n",
    "    cnn_cols = [f\"cnn_class_{i}\" for i in range(n_classes)]\n",
    "    nb_cols  = [f\"nb_class_{i}\"  for i in range(n_classes)]\n",
    "\n",
    "    # Get the probability values per class\n",
    "    cnn_val = val_merged[cnn_cols].values\n",
    "    nb_val  = val_merged[nb_cols].values\n",
    "    y_val   = val_merged[\"true_label_cnn\"].values  \n",
    "\n",
    "    cnn_test = test_merged[cnn_cols].values\n",
    "    nb_test  = test_merged[nb_cols].values\n",
    "    y_test   = test_merged[\"true_label_cnn\"].values\n",
    "\n",
    "    # Create the hstack table that will be needed for the regression \n",
    "    x_val  = np.hstack([cnn_val, nb_val])\n",
    "    x_test = np.hstack([cnn_test, nb_test])\n",
    "\n",
    "    # Train multinomial logistic regression\n",
    "    stacker = LogisticRegression(\n",
    "        multi_class=\"multinomial\",\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=1000\n",
    "    )\n",
    "    stacker.fit(x_val, y_val)\n",
    "\n",
    "    # Get the predicted & calibrated probs \n",
    "    stacked_val  = stacker.predict_proba(x_val)\n",
    "    stacked_test = stacker.predict_proba(x_test)\n",
    "\n",
    "    return stacked_val, stacked_test, y_val, y_test, stacker, x_val, x_test\n",
    "\n",
    "# Perform stacking \n",
    "stack_val, stack_test, y_val, y_test, stack_model, x_val, x_test = stacking_multinomial_from_frames(\n",
    "    cnn_preds_val, nb_preds_val,\n",
    "    cnn_preds_test, nb_preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55db66a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test (Stacking): 89.79166666666667%\n",
      "Accuracy Val (Stacking): 89.51041666666667%\n",
      "\n",
      "NLL Val (Stacking): 0.31831729276765564\n",
      "NLL Test (Stacking): 0.3044957661715265\n",
      "\n",
      "ECE Val (Stacking): 0.00985928522679883\n",
      "ECE Test (Stacking): 0.018243943249214904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for validation \n",
    "acc_stack_val = (np.argmax(stack_val, axis=1) == y_val).mean() * 100\n",
    "nll_stack_val = log_loss(y_val, stack_val, labels=np.arange(stack_val.shape[1]))\n",
    "ece_stack_val = ece_score(stack_val, y_val)\n",
    "\n",
    "# Calculate metrics for testing  \n",
    "acc_stack_test = (np.argmax(stack_test, axis=1) == y_test).mean() * 100\n",
    "nll_stack_test = log_loss(y_test, stack_test, labels=np.arange(stack_test.shape[1]))\n",
    "ece_stack_test = ece_score(stack_test, y_test)\n",
    "\n",
    "# All results for calibration using stacking (meta-learner)\n",
    "print(f\"Accuracy Test (Stacking): {acc_stack_test}%\")\n",
    "print(f\"Accuracy Val (Stacking): {acc_stack_val}%\")\n",
    "print()\n",
    "print(f\"NLL Val (Stacking): {nll_stack_val}\")\n",
    "print(f\"NLL Test (Stacking): {nll_stack_test}\")\n",
    "print()\n",
    "print(f\"ECE Val (Stacking): {ece_stack_val}\")\n",
    "print(f\"ECE Test (Stacking): {ece_stack_test}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02adeb0",
   "metadata": {},
   "source": [
    "Get coeffients of the meta learner (multinomial logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "72d46244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild meta-features outside the function \n",
    "n_classes = 10\n",
    "\n",
    "# Merge CNN & NB validation preds\n",
    "val_merged = cnn_preds_val.merge(nb_preds_val, on=\"id\", suffixes=(\"_cnn\", \"_nb\"))\n",
    "test_merged = cnn_preds_test.merge(nb_preds_test, on=\"id\", suffixes=(\"_cnn\", \"_nb\"))\n",
    "\n",
    "# Extract probability matrices\n",
    "cnn_val = val_merged[[f\"cnn_class_{i}\" for i in range(n_classes)]].values\n",
    "nb_val  = val_merged[[f\"nb_class_{i}\"  for i in range(n_classes)]].values\n",
    "cnn_test = test_merged[[f\"cnn_class_{i}\" for i in range(n_classes)]].values\n",
    "nb_test  = test_merged[[f\"nb_class_{i}\"  for i in range(n_classes)]].values\n",
    "\n",
    "# True labels\n",
    "y_val  = val_merged[\"true_label_cnn\"].values\n",
    "y_test = test_merged[\"true_label_cnn\"].values\n",
    "\n",
    "# Combine \n",
    "x_val  = np.hstack([cnn_val, nb_val])\n",
    "x_test = np.hstack([cnn_test, nb_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aff2ec61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ioannaioannidou/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Meta-learner Coefficients (per class) ===\n",
      "         cnn_class_0  cnn_class_1  cnn_class_2  cnn_class_3  cnn_class_4  \\\n",
      "class_0       4.1251      -1.1506       0.5634       0.0404      -1.2778   \n",
      "class_1      -1.3129       5.1700      -0.9208       0.3734      -0.4977   \n",
      "class_2       0.6188      -1.3470       4.4534      -1.1091       0.5421   \n",
      "class_3      -0.1255      -0.0054      -0.3862       3.9181       0.5120   \n",
      "class_4      -1.2108      -0.2570       0.6280       0.0314       4.5183   \n",
      "class_5      -1.1495      -0.5906      -0.9015      -0.9841      -1.0339   \n",
      "class_6       1.4946      -0.9054       0.2910      -0.2563      -0.3328   \n",
      "class_7      -1.1157      -0.5256      -1.1468      -1.0411      -0.8657   \n",
      "class_8      -0.1941       0.0725      -1.2748       0.1871      -0.6629   \n",
      "class_9      -1.1300      -0.4610      -1.3058      -1.1599      -0.9016   \n",
      "\n",
      "         cnn_class_5  cnn_class_6  cnn_class_7  cnn_class_8  cnn_class_9  \\\n",
      "class_0      -0.7696       1.2237      -0.9158      -0.9486      -0.8429   \n",
      "class_1      -0.5999      -0.9964      -0.7893       0.1121      -0.6816   \n",
      "class_2      -0.9741       0.3592      -1.2041      -0.3886      -0.9194   \n",
      "class_3      -1.0791      -0.0095      -1.3447      -0.4491      -0.8218   \n",
      "class_4      -0.9158       0.4563      -1.1602      -0.8878      -0.9190   \n",
      "class_5       5.4944      -1.3143       1.2030      -1.2535       0.3239   \n",
      "class_6      -1.1575       3.9503      -1.3349      -0.3592      -1.0387   \n",
      "class_7      -0.1756      -1.2974       4.6882       0.0862       0.9679   \n",
      "class_8       0.3152      -1.0498      -0.5466       4.3532      -1.1048   \n",
      "class_9      -0.1379      -1.3222       1.4043      -0.2647       5.0364   \n",
      "\n",
      "         nb_class_0  nb_class_1  nb_class_2  nb_class_3  nb_class_4  \\\n",
      "class_0      3.6728      1.2794     -0.8174     -0.6455     -1.9491   \n",
      "class_1     -0.0412      3.1990     -0.3610      1.4818     -0.3881   \n",
      "class_2     -0.0649     -0.6406      3.0459     -0.4509      0.6551   \n",
      "class_3      0.8693      0.0776     -0.5037      2.7985     -0.2750   \n",
      "class_4     -2.4716     -0.1234      0.8116      0.5417      2.9422   \n",
      "class_5     -0.7632     -0.3102     -1.0502     -0.3666     -0.9177   \n",
      "class_6      0.6304     -1.1766      0.0998     -0.4978      1.4266   \n",
      "class_7     -0.7031     -0.4909     -0.8993     -0.9324     -0.7844   \n",
      "class_8     -0.4485     -1.2625      0.6280     -0.9998      0.1475   \n",
      "class_9     -0.6802     -0.5517     -0.9537     -0.9292     -0.8571   \n",
      "\n",
      "         nb_class_5  nb_class_6  nb_class_7  nb_class_8  nb_class_9  \n",
      "class_0     -1.7506      1.0213     -0.6042      0.2014     -0.3609  \n",
      "class_1     -1.7756     -0.2812     -1.2060     -0.1441     -0.6267  \n",
      "class_2      0.1597      0.3931     -0.3759     -1.5460     -1.1442  \n",
      "class_3     -0.3870      0.7896     -0.2774     -2.0224     -0.8605  \n",
      "class_4     -0.9390      0.7176     -0.8966      0.5607     -0.8599  \n",
      "class_5      2.6738     -1.2791      0.5631     -0.0961      1.3401  \n",
      "class_6     -0.0190      2.1863     -1.6059      0.3162     -1.0089  \n",
      "class_7      1.7130     -1.2366      3.4000     -0.8104      0.3184  \n",
      "class_8      0.4411     -1.0533     -0.0622      3.3307     -0.6260  \n",
      "class_9     -0.1163     -1.2576      1.0649      0.2099      3.8285  \n"
     ]
    }
   ],
   "source": [
    "stack_model.fit(x_val, y_val)\n",
    "feature_names = [f\"cnn_class_{i}\" for i in range(n_classes)] + [f\"nb_class_{i}\" for i in range(n_classes)]\n",
    "\n",
    "coef_df = pd.DataFrame(stack_model.coef_, columns=feature_names)\n",
    "coef_df.index = [f\"class_{i}\" for i in range(n_classes)]\n",
    "\n",
    "print(\"\\n=== Meta-learner Coefficients (per class) ===\")\n",
    "print(coef_df.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8d0d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average |Coef| magnitude:\n",
      "  CNN features:  1.1503\n",
      "  NB features:   0.9907\n"
     ]
    }
   ],
   "source": [
    "# Average coefficient magnitude per model (absolute - ignore the signs)\n",
    "# absolute value removes cancellation, capturing the magnitude of influence\n",
    "cnn_importance = coef_df[[c for c in coef_df.columns if \"cnn\" in c]].abs().mean().mean()\n",
    "nb_importance  = coef_df[[c for c in coef_df.columns if \"nb\"  in c]].abs().mean().mean()\n",
    "\n",
    "print(f\"\\nAverage |Coef| magnitude:\")\n",
    "print(f\"  CNN features:  {cnn_importance:.4f}\")\n",
    "print(f\"  NB features:   {nb_importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65c26843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Class   |   CNN |Coef| Mean |   NB |Coef| Mean | Preferred Model   |\n",
      "|:--------|------------------:|-----------------:|:------------------|\n",
      "| class_0 |             1.186 |            1.23  | NB                |\n",
      "| class_1 |             1.145 |            0.95  | CNN               |\n",
      "| class_2 |             1.192 |            0.848 | CNN               |\n",
      "| class_3 |             0.865 |            0.886 | NB                |\n",
      "| class_4 |             1.098 |            1.086 | CNN               |\n",
      "| class_5 |             1.425 |            0.936 | CNN               |\n",
      "| class_6 |             1.112 |            0.897 | CNN               |\n",
      "| class_7 |             1.191 |            1.129 | CNN               |\n",
      "| class_8 |             0.976 |            0.9   | CNN               |\n",
      "| class_9 |             1.312 |            1.045 | CNN               |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/qnrb3lm539nfznyv5cmr8rph0000gn/T/ipykernel_67106/850195543.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  \"CNN\" if cnn_per_class[i] > nb_per_class[i] else \"NB\"\n"
     ]
    }
   ],
   "source": [
    "# Average coefficient magnitude per model (absolute - ignore the signs)\n",
    "cnn_per_class = coef_df[[f\"cnn_class_{i}\" for i in range(n_classes)]].abs().mean(axis=1)\n",
    "nb_per_class  = coef_df[[f\"nb_class_{i}\"  for i in range(n_classes)]].abs().mean(axis=1)\n",
    "\n",
    "# Compare them\n",
    "pref_df = pd.DataFrame({\n",
    "    \"Class\": coef_df.index,\n",
    "    \"CNN |Coef| Mean\": cnn_per_class.round(3),\n",
    "    \"NB |Coef| Mean\": nb_per_class.round(3),\n",
    "    \"Preferred Model\": [\n",
    "        \"CNN\" if cnn_per_class[i] > nb_per_class[i] else \"NB\"\n",
    "        for i in range(len(coef_df))]})\n",
    "\n",
    "print(pref_df.to_markdown(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574ac1ae",
   "metadata": {},
   "source": [
    "# SUMMARY FULL IMAGE\n",
    "\n",
    "### Full Images – Combination Results\n",
    "\n",
    "| Metric Direction | **↑ Accuracy** | **↓ NLL** | **↓ ECE** |\n",
    "|:-------------------|:--------------:|:----------:|:----------:|\n",
    "| **Individual Models (for reference)** | | | |\n",
    "| Bayesian (BLR) | 54.63% | 0.8906 | 0.0197 |\n",
    "| CNN (Calibrated)| 89.19% | 0.3113 | 0.0181 |\n",
    "| **Combination Methods** | | | |\n",
    "| Simple Average (50/50) | Val = 89.04%, Test = 89.35% | Val = 0.4819, Test = 0.4688 | Val = 0.1796, Test = 0.1835 |\n",
    "| Weighted Average (AUC-based) | Val = 89.11%, Test = 89.44% | Val = 0.4111, Test = 0.3975 | Val = 0.1210, Test = 0.1251 |\n",
    "| Stacking (Meta-Model) | Val = 89.51%, Test = 89.79% | Val = 0.3183, Test = 0.3045 | Val = 0.0099, Test = 0.0182 |\n",
    "\n",
    "Observations:\n",
    "- CNN performs strongly on its own (~89% accuracy), while the Bayesian model is much weaker (~55%).  \n",
    "- All combination methods outperform individual models.  \n",
    "- The Stacking meta-model achieves the best calibration (lowest ECE) and lowest NLL, with a good in accuracy.  \n",
    "- This shows that the meta-learner effectively learns when to trust CNN vs Bayes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bfeeb0",
   "metadata": {},
   "source": [
    "### Meta-Learner Coefficient Summary — Full Images\n",
    "| Metric | CNN Features | NB Features |\n",
    "|:-------|:-------------:|:------------:|\n",
    "| **Average \\|Coef\\| Magnitude** | **1.1503** | **0.9907** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b07a87f",
   "metadata": {},
   "source": [
    "| Class | CNN \\|Coef\\ Mean | NB \\|Coef\\ Mean | Preferred Model |\n",
    "|:------|------------------:|-----------------:|:----------------|\n",
    "| class_0 | 1.186 | 1.230 | NB |\n",
    "| class_1 | 1.145 | 0.950 | CNN |\n",
    "| class_2 | 1.192 | 0.848 | CNN |\n",
    "| class_3 | 0.865 | 0.886 | NB |\n",
    "| class_4 | 1.098 | 1.086 | CNN |\n",
    "| class_5 | 1.425 | 0.936 | CNN |\n",
    "| class_6 | 1.112 | 0.897 | CNN |\n",
    "| class_7 | 1.191 | 1.129 | CNN |\n",
    "| class_8 | 0.976 | 0.900 | CNN |\n",
    "| class_9 | 1.312 | 1.045 | CNN |\n",
    "\n",
    "Mostly relies on the CNN, with consistently higher coefficients across most classes.\n",
    "The Naive Bayes model contributes to two classes (class 0 and 3), but overall, the CNN dominates the combination strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc0efdd",
   "metadata": {},
   "source": [
    "# SUMMARY DROPOUT IMAGES\n",
    "\n",
    "### Dropout Images – Combination Results\n",
    "\n",
    "\n",
    "| Metric Direction | **↑ Accuracy** | **↓ NLL** | **↓ ECE** |\n",
    "|:-----------------|:--------------:|:----------:|:----------:|\n",
    "| **Individual Models (for reference)** | | | |\n",
    "| Bayesian (BLR) | 57.37% | 0.8715 | 0.0290 |\n",
    "| CNN (Calibrated) | 89.19% | 0.3113 | 0.0181 |\n",
    "| **Combination Methods** | | | |\n",
    "| Simple Average (50/50) | Val = 78.19%, Test = 77.38% | Val = 0.5984, Test = 0.6036 | Val = 0.0927, Test = 0.0875 |\n",
    "| Weighted Average (AUC-based) | Val = 78.01%, Test = 77.13% | Val = 0.5842, Test = 0.5895 | Val = 0.0708, Test = 0.0745 |\n",
    "| Stacking (Meta-Model) | Val = 82.80%, Test = 82.29% | Val = 0.4587, Test = 0.4721 | Val = 0.0125, Test = 0.0123 |\n",
    "\n",
    "Observations: \n",
    "- With degraded images, both individual models lose accuracy as expected, however CNN remains stronger.\n",
    "- The Stacking meta-model again provides the best balance. Even with degraded images is well colibrated (ECE ~0.012)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43753a4",
   "metadata": {},
   "source": [
    "### Meta-Learner Coefficient Summary — Degraded Images\n",
    "\n",
    "| Metric | CNN Features | NB Features |\n",
    "|:-------|:-------------:|:------------:|\n",
    "| **Average \\|Coef\\| Magnitude** | **1.1896** | **1.1933** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af83978f",
   "metadata": {},
   "source": [
    "| Class | CNN \\|Coef\\ Mean | NB \\|Coef\\ Mean | Preferred Model |\n",
    "|:------|------------------:|-----------------:|:----------------|\n",
    "| class_0 | 1.206 | 1.289 | NB |\n",
    "| class_1 | 0.871 | 1.231 | NB |\n",
    "| class_2 | 1.181 | 0.970 | CNN |\n",
    "| class_3 | 1.325 | 1.084 | CNN |\n",
    "| class_4 | 1.217 | 1.951 | NB |\n",
    "| class_5 | 1.381 | 1.070 | CNN |\n",
    "| class_6 | 1.230 | 1.182 | CNN |\n",
    "| class_7 | 1.432 | 1.193 | CNN |\n",
    "| class_8 | 0.986 | 0.973 | CNN |\n",
    "| class_9 | 1.066 | 0.989 | CNN |\n",
    "\n",
    "For degraded images, the meta-learner is more balanced, giving nearly equal overall weight to CNN and Naive Bayes features.\n",
    "It trusts more the Bayes model for classes (0, 1, and 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e6509e",
   "metadata": {},
   "source": [
    "# Train several meta learners \n",
    "Important to mention that i combined the predictions of CNN and BLR for both full and drop out images and all these 4 columns for 10 classes will be the 40 features that will be used to train a new meta learner. \n",
    "\n",
    "- A static one (Logistic Regression) that will learn the weights for each model and whether is a full or drop out images and apply it to make new predicions\n",
    "\n",
    "- A dynamic one (Random Forest and Gradient Boosting) that will learn to adjust the weights based on the patterns observed in the input features\n",
    "\n",
    "Since it combines the predictions from both full and degraded images it can be considered as a kind of data augmentation where the meta-model sees a wider range of inputs and learns to handle uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27403551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bb8fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv files containing the predictions\n",
    "def load_preds(path, prefix):\n",
    "    df = pd.read_csv(path).copy()\n",
    "    if \"true_label\" not in df.columns and \"label\" in df.columns:\n",
    "        df = df.rename(columns={\"label\": \"true_label\"})\n",
    "    prob_cols = [c for c in df.columns if \"_class_\" in c]\n",
    "    for c in prob_cols:\n",
    "        idx = c.split(\"_\")[-1]\n",
    "        df = df.rename(columns={c: f\"{prefix}_class_{idx}\"})\n",
    "    if \"id\" not in df.columns:\n",
    "        df.insert(0, \"id\", np.arange(len(df)))\n",
    "    return df\n",
    "\n",
    "cnn_full_train = load_preds(\"cnn_comb_train_calibrated_predictions.csv\", \"cnn_full\")\n",
    "cnn_full_test  = load_preds(\"cnn_comb_test_calibrated_predictions.csv\", \"cnn_full\")\n",
    "\n",
    "cnn_drop_train = load_preds(\"cnn_dropout_comb_train_calibrated_predictions.csv\", \"cnn_drop\")\n",
    "cnn_drop_test  = load_preds(\"cnn_dropout_comb_test_calibrated_predictions.csv\", \"cnn_drop\")\n",
    "\n",
    "blr_full_train = load_preds(\"blr_full_comb_train_predictions.csv\", \"blr_full\")\n",
    "blr_full_test  = load_preds(\"blr_full_comb_test_predictions.csv\", \"blr_full\")\n",
    "\n",
    "blr_drop_train = load_preds(\"blr_dropout_comb_train_predictions.csv\", \"blr_drop\")\n",
    "blr_drop_test  = load_preds(\"blr_dropout_comb_test_predictions.csv\", \"blr_drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83c6a37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (19200, 45) Test: (4800, 45)\n"
     ]
    }
   ],
   "source": [
    "# Clean up duplicate true_label columns before merging otherwise python complaints  \n",
    "def drop_extra_labels(df):\n",
    "    cols = [c for c in df.columns if \"true_label\" in c]\n",
    "    if len(cols) > 1:\n",
    "        df = df.drop(columns=cols[1:])\n",
    "    return df\n",
    "\n",
    "cnn_full_train = drop_extra_labels(cnn_full_train)\n",
    "cnn_drop_train = drop_extra_labels(cnn_drop_train)\n",
    "blr_full_train = drop_extra_labels(blr_full_train)\n",
    "blr_drop_train = drop_extra_labels(blr_drop_train)\n",
    "\n",
    "cnn_full_test = drop_extra_labels(cnn_full_test)\n",
    "cnn_drop_test = drop_extra_labels(cnn_drop_test)\n",
    "blr_full_test = drop_extra_labels(blr_full_test)\n",
    "blr_drop_test = drop_extra_labels(blr_drop_test)\n",
    "\n",
    "# Merge datasets on id\n",
    "train_df = (\n",
    "    cnn_full_train\n",
    "    .merge(cnn_drop_train, on=\"id\", suffixes=(\"\", \"_dup1\"))\n",
    "    .merge(blr_full_train, on=\"id\", suffixes=(\"\", \"_dup2\"))\n",
    "    .merge(blr_drop_train, on=\"id\", suffixes=(\"\", \"_dup3\")))\n",
    "\n",
    "test_df = (\n",
    "    cnn_full_test\n",
    "    .merge(cnn_drop_test, on=\"id\", suffixes=(\"\", \"_dup1\"))\n",
    "    .merge(blr_full_test, on=\"id\", suffixes=(\"\", \"_dup2\"))\n",
    "    .merge(blr_drop_test, on=\"id\", suffixes=(\"\", \"_dup3\")))\n",
    "\n",
    "print(\"Train:\", train_df.shape, \"Test:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb9d5980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ioannaioannidou/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Split dependent and independent vars \n",
    "feature_cols = [c for c in train_df.columns if \"_class_\" in c]\n",
    "X_train = train_df[feature_cols].values\n",
    "y_train = train_df[\"true_label\"].values \n",
    "X_test  = test_df[feature_cols].values\n",
    "y_test  = test_df[\"true_label\"].values\n",
    "\n",
    "print(\"Features:\", len(feature_cols))\n",
    "\n",
    "# Meta-learners used \n",
    "models = {\n",
    "    \"LogReg\": LogisticRegression(max_iter=1000, multi_class=\"multinomial\"),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=200, max_depth=None, random_state=0),\n",
    "    \"GBM\": GradientBoostingClassifier(n_estimators=300, learning_rate=0.05, max_depth=3, random_state=0)}\n",
    "\n",
    "# Fit, test each of them and evaluate them \n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    probs_val = model.predict_proba(X_train)\n",
    "    probs_test = model.predict_proba(X_test)\n",
    "\n",
    "    acc_val = (np.argmax(probs_val, 1) == y_train).mean() * 100\n",
    "    acc_test = (np.argmax(probs_test, 1) == y_test).mean() * 100\n",
    "    nll_val = log_loss(y_train, probs_val, labels=np.arange(probs_val.shape[1]))\n",
    "    nll_test = log_loss(y_test, probs_test, labels=np.arange(probs_test.shape[1]))\n",
    "    ece_val = ece_score(probs_val, y_train)\n",
    "    ece_test = ece_score(probs_test, y_test)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy (Val)\": acc_val,\n",
    "        \"Accuracy (Test)\": acc_test,\n",
    "        \"NLL (Val)\": nll_val,\n",
    "        \"NLL (Test)\": nll_test,\n",
    "        \"ECE (Val)\": ece_val,\n",
    "        \"ECE (Test)\": ece_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ec5f749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_a8c00\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a8c00_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_a8c00_level0_col1\" class=\"col_heading level0 col1\" >Accuracy (Val)</th>\n",
       "      <th id=\"T_a8c00_level0_col2\" class=\"col_heading level0 col2\" >Accuracy (Test)</th>\n",
       "      <th id=\"T_a8c00_level0_col3\" class=\"col_heading level0 col3\" >NLL (Val)</th>\n",
       "      <th id=\"T_a8c00_level0_col4\" class=\"col_heading level0 col4\" >NLL (Test)</th>\n",
       "      <th id=\"T_a8c00_level0_col5\" class=\"col_heading level0 col5\" >ECE (Val)</th>\n",
       "      <th id=\"T_a8c00_level0_col6\" class=\"col_heading level0 col6\" >ECE (Test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a8c00_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a8c00_row0_col0\" class=\"data row0 col0\" >LogReg</td>\n",
       "      <td id=\"T_a8c00_row0_col1\" class=\"data row0 col1\" >89.71%</td>\n",
       "      <td id=\"T_a8c00_row0_col2\" class=\"data row0 col2\" >89.81%</td>\n",
       "      <td id=\"T_a8c00_row0_col3\" class=\"data row0 col3\" >0.3007</td>\n",
       "      <td id=\"T_a8c00_row0_col4\" class=\"data row0 col4\" >0.2988</td>\n",
       "      <td id=\"T_a8c00_row0_col5\" class=\"data row0 col5\" >0.0065</td>\n",
       "      <td id=\"T_a8c00_row0_col6\" class=\"data row0 col6\" >0.0097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a8c00_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a8c00_row1_col0\" class=\"data row1 col0\" >RF</td>\n",
       "      <td id=\"T_a8c00_row1_col1\" class=\"data row1 col1\" >100.00%</td>\n",
       "      <td id=\"T_a8c00_row1_col2\" class=\"data row1 col2\" >90.29%</td>\n",
       "      <td id=\"T_a8c00_row1_col3\" class=\"data row1 col3\" >0.0687</td>\n",
       "      <td id=\"T_a8c00_row1_col4\" class=\"data row1 col4\" >0.3228</td>\n",
       "      <td id=\"T_a8c00_row1_col5\" class=\"data row1 col5\" >0.0608</td>\n",
       "      <td id=\"T_a8c00_row1_col6\" class=\"data row1 col6\" >0.0264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a8c00_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a8c00_row2_col0\" class=\"data row2 col0\" >GBM</td>\n",
       "      <td id=\"T_a8c00_row2_col1\" class=\"data row2 col1\" >95.19%</td>\n",
       "      <td id=\"T_a8c00_row2_col2\" class=\"data row2 col2\" >89.60%</td>\n",
       "      <td id=\"T_a8c00_row2_col3\" class=\"data row2 col3\" >0.1474</td>\n",
       "      <td id=\"T_a8c00_row2_col4\" class=\"data row2 col4\" >0.2999</td>\n",
       "      <td id=\"T_a8c00_row2_col5\" class=\"data row2 col5\" >0.0325</td>\n",
       "      <td id=\"T_a8c00_row2_col6\" class=\"data row2 col6\" >0.0235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1514c3010>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary \n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df.style.format({\n",
    "    \"Accuracy (Val)\": \"{:.2f}%\",\n",
    "    \"Accuracy (Test)\": \"{:.2f}%\",\n",
    "    \"NLL (Val)\": \"{:.4f}\",\n",
    "    \"NLL (Test)\": \"{:.4f}\",\n",
    "    \"ECE (Val)\": \"{:.4f}\",\n",
    "    \"ECE (Test)\": \"{:.4f}\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849a9431",
   "metadata": {},
   "source": [
    " Check the coefficients or importance given to each model (CNN or BLR) and image type (full or degraded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f80a585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Feature Importance\n",
      "source\n",
      "CNN (Full)    1.150284\n",
      "CNN (Drop)    0.990734\n",
      "Name: importance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Extract absolute coefficients\n",
    "coef = np.abs(stack_model.coef_)  \n",
    "avg_importance = coef.mean(axis=0)\n",
    "\n",
    "# number of features\n",
    "n_features = avg_importance.shape[0]\n",
    "feature_names_used = feature_cols[:n_features] \n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names_used,\n",
    "    'importance': avg_importance})\n",
    "\n",
    "# Group features by model and image source\n",
    "importance_df['source'] = importance_df['feature'].apply(\n",
    "    lambda f: (\n",
    "        'CNN (Full)' if 'cnn_full' in f else\n",
    "        'CNN (Drop)' if 'cnn_drop' in f else\n",
    "        'BLR (Full)' if 'blr_full' in f else\n",
    "        'BLR (Drop)' if 'blr_drop' in f else 'Other'))\n",
    "\n",
    "# Aggregate importance\n",
    "grouped = importance_df.groupby('source')['importance'].mean().sort_values(ascending=False)\n",
    "print(\"Logistic Regression Feature Importance\")\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a491a429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(learning_rate=0.05, n_estimators=300, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GradientBoostingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('loss',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">loss&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;log_loss&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.05</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">300</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;friedman_mse&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('init',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">init&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validation_fraction',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validation_fraction&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_iter_no_change',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_iter_no_change&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.05, n_estimators=300, random_state=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit each meta-learner outside the function\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=None, random_state=0)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "gbm_model = GradientBoostingClassifier(n_estimators=300, learning_rate=0.05, max_depth=3, random_state=0)\n",
    "gbm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a559d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: feature mismatch (10 shap vs 40 features)\n",
      "Random Forest SHAP Feature Importance\n",
      "source\n",
      "CNN (Full)    0.006474\n",
      "Name: importance, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Random Forest Feature Importance by Source'}, ylabel='source'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## UNEXPECTED RESULTS - 10 SHAP FOUND VS 40 ??\n",
    "## Any way also to make it choose more often the BLR\n",
    "import shap\n",
    "\n",
    "# SHAP explainer\n",
    "explainer_rf = shap.TreeExplainer(rf_model)\n",
    "shap_values_rf = explainer_rf.shap_values(X_test)  \n",
    "\n",
    "# Mean absolute SHAP values \n",
    "shap_values_rf_stacked = np.stack(shap_values_rf, axis=0)\n",
    "mean_abs_shap_rf = np.mean(np.abs(shap_values_rf_stacked), axis=(0, 1))  # shape: (n_features,)\n",
    "\n",
    "if len(mean_abs_shap_rf) != len(feature_cols):\n",
    "    print(f\"Warning: feature mismatch ({len(mean_abs_shap_rf)} shap vs {len(feature_cols)} features)\")\n",
    "    feature_cols = feature_cols[:len(mean_abs_shap_rf)]\n",
    "\n",
    "importance_df_rf = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': mean_abs_shap_rf})\n",
    "\n",
    "# Group features by model and image type\n",
    "importance_df_rf['source'] = importance_df_rf['feature'].apply(\n",
    "    lambda f: (\n",
    "        'CNN (Full)' if 'cnn_full' in f else\n",
    "        'CNN (Drop)' if 'cnn_drop' in f else\n",
    "        'BLR (Full)' if 'blr_full' in f else\n",
    "        'BLR (Drop)' if 'blr_drop' in f else 'Other'))\n",
    "\n",
    "# Aggregate\n",
    "grouped_rf = importance_df_rf.groupby('source')['importance'].mean().sort_values(ascending=False)\n",
    "print(\"Random Forest SHAP Feature Importance\")\n",
    "print(grouped_rf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d073c26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 4801it [46:56,  1.70it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Gradient Boosting SHAP Feature Influence ===\n",
      "source\n",
      "CNN (Full)    0.015465\n",
      "Name: importance, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Gradient Boosting Feature Importance by Source'}, ylabel='source'>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## UNEXPECTED RESULTS \n",
    "## Any way also to make it choose more often the BLR\n",
    "\n",
    "# RF\n",
    "predict_fn = gbm_model.predict_proba\n",
    "\n",
    "# SHAP \n",
    "explainer_gbm = shap.Explainer(predict_fn, X_test, algorithm='permutation')\n",
    "shap_values_gbm = explainer_gbm(X_test)\n",
    "\n",
    "# Multi-class SHAP (n_samples, n_features, n_classes)\n",
    "shap_vals = shap_values_gbm.values\n",
    "if shap_vals.ndim == 3:\n",
    "    mean_abs_shap_gbm = np.abs(shap_vals).mean(axis=(0, 2))\n",
    "else:\n",
    "    mean_abs_shap_gbm = np.abs(shap_vals).mean(axis=0)\n",
    "\n",
    "# Align feature lengths \n",
    "n_features = min(len(feature_cols), len(mean_abs_shap_gbm))\n",
    "feature_names = feature_cols[:n_features]\n",
    "mean_abs_shap_gbm = mean_abs_shap_gbm[:n_features]\n",
    "\n",
    "importance_df_gbm = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': mean_abs_shap_gbm})\n",
    "\n",
    "# Assign labels\n",
    "importance_df_gbm['source'] = importance_df_gbm['feature'].apply(\n",
    "    lambda f: (\n",
    "        'CNN (Full)' if 'cnn_full' in f else\n",
    "        'CNN (Drop)' if 'cnn_drop' in f else\n",
    "        'BLR (Full)' if 'blr_full' in f else\n",
    "        'BLR (Drop)' if 'blr_drop' in f else 'Other'))\n",
    "\n",
    "# Aggregate\n",
    "grouped_gbm = importance_df_gbm.groupby('source')['importance'].mean().sort_values(ascending=False)\n",
    "print(\"Gradient Boosting SHAP Feature Importance\")\n",
    "print(grouped_gbm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a6cb29",
   "metadata": {},
   "source": [
    "### Meta-Learner (Full & Dropout Images Predictions)\n",
    "\n",
    "### Overall Performance Comparison — Full vs Degraded Images\n",
    "\n",
    "| Metric Direction | **↑ Accuracy** | **↓ NLL** | **↓ ECE** |\n",
    "|:-------------------|:--------------:|:----------:|:----------:|\n",
    "| Bayesian (BLR, Full Images) | Test = 54.63% | Test = 0.8906 | Test = 0.0197 |\n",
    "| Bayesian (BLR, Degraded Images) | Test = 57.37% | Test = 0.8715 | Test = 0.0290 |\n",
    "| CNN (Calibrated, Full Images) | Test = 89.19% | Test = 0.3113 | Test = 0.0181 |\n",
    "| CNN (Calibrated, Degraded Images) | Test = 89.19% | Test = 0.3113 | Test = 0.0181 |\n",
    "| Logistic Regression (Meta-Learner) | Val = 89.71%, Test = 89.81% | Val = 0.3007, Test = 0.2988 | Val = 0.0065, Test = 0.0097 |\n",
    "| Random Forest (Meta-Learner) | Val = 100.00%, Test = 90.29% | Val = 0.0687, Test = 0.3228 | Val = 0.0608, Test = 0.0264 |\n",
    "| Gradient Boosting (Meta-Learner) | Val = 95.19%, Test = 89.60% | Val = 0.1474, Test = 0.2999 | Val = 0.0325, Test = 0.0235 |\n",
    "\n",
    "\n",
    "- Logistic Regression provides the best generalization (lowest NLL & ECE on both val/test)\n",
    "- Random Forest clearly overfits (100% Val Acc but drop on Test + higher NLL)\n",
    "- Gradient Boosting performs well, slightly under LogReg, showing slight overfitting too \n",
    "\n",
    "Logistic Regression is the best for now (static) for the other nonlinear cases i should optimise them to improve generalisation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
